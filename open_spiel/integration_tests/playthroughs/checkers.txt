game: checkers

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Checkers"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["columns", "rows"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "checkers"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 2048
PolicyTensorShape() = [2048]
MaxChanceOutcomes() = 0
GetParameters() = {columns=8,rows=8}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [5, 8, 8]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 320
MaxGameLength() = 1000
ToString() = "checkers()"

# State 0
# 8.+.+.+.+
# 7+.+.+.+.
# 6.+.+.+.+
# 5........
# 4........
# 3o.o.o.o.
# 2.o.o.o.o
# 1o.o.o.o.
#  abcdefgh
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "8.+.+.+.+\n7+.+.+.+.\n6.+.+.+.+\n5........\n4........\n3o.o.o.o.\n2.o.o.o.o\n1o.o.o.o.\n abcdefgh\n"
ObservationString(1) = "8.+.+.+.+\n7+.+.+.+.\n6.+.+.+.+\n5........\n4........\n3o.o.o.o.\n2.o.o.o.o\n1o.o.o.o.\n abcdefgh\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
ObservationTensor(1):
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [1288, 1344, 1352, 1408, 1416, 1472, 1480]
StringLegalActions() = ["a3b4", "c3b4", "c3d4", "e3d4", "e3f4", "g3f4", "g3h4"]

# Apply action "g3f4"
action: 1472

# State 1
# 8.+.+.+.+
# 7+.+.+.+.
# 6.+.+.+.+
# 5........
# 4.....o..
# 3o.o.o...
# 2.o.o.o.o
# 1o.o.o.o.
#  abcdefgh
IsTerminal() = False
History() = [1472]
HistoryString() = "1472"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1472"
InformationStateString(1) = "1472"
ObservationString(0) = "8.+.+.+.+\n7+.+.+.+.\n6.+.+.+.+\n5........\n4.....o..\n3o.o.o...\n2.o.o.o.o\n1o.o.o.o.\n abcdefgh\n"
ObservationString(1) = "8.+.+.+.+\n7+.+.+.+.\n6.+.+.+.+\n5........\n4.....o..\n3o.o.o...\n2.o.o.o.o\n1o.o.o.o.\n abcdefgh\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉
◉◯◉◯◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◉◉
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
ObservationTensor(1):
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯  ◯◉◯◉◯◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [560, 568, 624, 632, 688, 696, 760]
StringLegalActions() = ["b6c5", "b6a5", "d6e5", "d6c5", "f6g5", "f6e5", "h6g5"]

# Apply action "b6a5"
action: 568

# State 2
# 8.+.+.+.+
# 7+.+.+.+.
# 6...+.+.+
# 5+.......
# 4.....o..
# 3o.o.o...
# 2.o.o.o.o
# 1o.o.o.o.
#  abcdefgh
IsTerminal() = False
History() = [1472, 568]
HistoryString() = "1472, 568"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1472, 568"
InformationStateString(1) = "1472, 568"
ObservationString(0) = "8.+.+.+.+\n7+.+.+.+.\n6...+.+.+\n5+.......\n4.....o..\n3o.o.o...\n2.o.o.o.o\n1o.o.o.o.\n abcdefgh\n"
ObservationString(1) = "8.+.+.+.+\n7+.+.+.+.\n6...+.+.+\n5+.......\n4.....o..\n3o.o.o...\n2.o.o.o.o\n1o.o.o.o.\n abcdefgh\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◉◯◉  ◉◉◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉
◉◯◉◯◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◉◉
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
ObservationTensor(1):
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
◯◯◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯  ◯◉◯◉◯◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [1184, 1192, 1288, 1344, 1352, 1408, 1704, 1760]
StringLegalActions() = ["f4e5", "f4g5", "a3b4", "c3b4", "c3d4", "e3d4", "f2g3", "h2g3"]

# Apply action "f2g3"
action: 1704

# State 3
# 8.+.+.+.+
# 7+.+.+.+.
# 6...+.+.+
# 5+.......
# 4.....o..
# 3o.o.o.o.
# 2.o.o...o
# 1o.o.o.o.
#  abcdefgh
IsTerminal() = False
History() = [1472, 568, 1704]
HistoryString() = "1472, 568, 1704"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1472, 568, 1704"
InformationStateString(1) = "1472, 568, 1704"
ObservationString(0) = "8.+.+.+.+\n7+.+.+.+.\n6...+.+.+\n5+.......\n4.....o..\n3o.o.o.o.\n2.o.o...o\n1o.o.o.o.\n abcdefgh\n"
ObservationString(1) = "8.+.+.+.+\n7+.+.+.+.\n6...+.+.+\n5+.......\n4.....o..\n3o.o.o.o.\n2.o.o...o\n1o.o.o.o.\n abcdefgh\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◉◯◉  ◉◉◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
◯◉◯◉◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◉◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
ObservationTensor(1):
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
◯◯◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◯◯◉  ◉◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [272, 344, 624, 632, 688, 696, 760, 784]
StringLegalActions() = ["a7b6", "c7b6", "d6e5", "d6c5", "f6g5", "f6e5", "h6g5", "a5b4"]

# Apply action "f6g5"
action: 688

# State 4
# 8.+.+.+.+
# 7+.+.+.+.
# 6...+...+
# 5+.....+.
# 4.....o..
# 3o.o.o.o.
# 2.o.o...o
# 1o.o.o.o.
#  abcdefgh
IsTerminal() = True
History() = [1472, 568, 1704, 688]
HistoryString() = "1472, 568, 1704, 688"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "1472, 568, 1704, 688"
InformationStateString(1) = "1472, 568, 1704, 688"
ObservationString(0) = "8.+.+.+.+\n7+.+.+.+.\n6...+...+\n5+.....+.\n4.....o..\n3o.o.o.o.\n2.o.o...o\n1o.o.o.o.\n abcdefgh\n"
ObservationString(1) = "8.+.+.+.+\n7+.+.+.+.\n6...+...+\n5+.....+.\n4.....o..\n3o.o.o.o.\n2.o.o...o\n1o.o.o.o.\n abcdefgh\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◉◯◉◯◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◉  ◉◉◉◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯  ◯◉◉◉◉◉◯◉
◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
◯◉◯◉◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◉◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
ObservationTensor(1):
◯◉◯◉◯◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯
◉◯◉◯◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉
◯◯◯◉◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◯◉◉◉◯
◉◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◯◉◯◯◯◉  ◉◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
Rewards() = [0, 0]
Returns() = [0, 0]
