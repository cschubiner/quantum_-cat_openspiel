game: nim

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Nim"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["is_misere", "pile_sizes"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "nim"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 29
PolicyTensorShape() = [29]
MaxChanceOutcomes() = 0
GetParameters() = {is_misere=True,pile_sizes=1;3;5;7}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [83]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 83
MaxGameLength() = 16
ToString() = "nim()"

# State 0
# 1 3 5 7
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "1 3 5 7"
ObservationString(1) = "1 3 5 7"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◉◉
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◉◉
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 14, 15, 18, 19, 23, 27]
StringLegalActions() = ["pile:1, take:1;", "pile:2, take:1;", "pile:3, take:1;", "pile:4, take:1;", "pile:2, take:2;", "pile:3, take:2;", "pile:4, take:2;", "pile:2, take:3;", "pile:3, take:3;", "pile:4, take:3;", "pile:3, take:4;", "pile:4, take:4;", "pile:3, take:5;", "pile:4, take:5;", "pile:4, take:6;", "pile:4, take:7;"]

# Apply action "pile:4, take:3;"
action: 11

# State 1
# 1 3 5 4
IsTerminal() = False
History() = [11]
HistoryString() = "11"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "11"
InformationStateString(1) = "11"
ObservationString(0) = "1 3 5 4"
ObservationString(1) = "1 3 5 4"
ObservationTensor(0): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 14, 15, 18]
StringLegalActions() = ["pile:1, take:1;", "pile:2, take:1;", "pile:3, take:1;", "pile:4, take:1;", "pile:2, take:2;", "pile:3, take:2;", "pile:4, take:2;", "pile:2, take:3;", "pile:3, take:3;", "pile:4, take:3;", "pile:3, take:4;", "pile:4, take:4;", "pile:3, take:5;"]

# Apply action "pile:3, take:1;"
action: 2

# State 2
# 1 3 4 4
IsTerminal() = False
History() = [11, 2]
HistoryString() = "11, 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "11, 2"
InformationStateString(1) = "11, 2"
ObservationString(0) = "1 3 4 4"
ObservationString(1) = "1 3 4 4"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 14, 15]
StringLegalActions() = ["pile:1, take:1;", "pile:2, take:1;", "pile:3, take:1;", "pile:4, take:1;", "pile:2, take:2;", "pile:3, take:2;", "pile:4, take:2;", "pile:2, take:3;", "pile:3, take:3;", "pile:4, take:3;", "pile:3, take:4;", "pile:4, take:4;"]

# Apply action "pile:2, take:1;"
action: 1

# State 3
# 1 2 4 4
IsTerminal() = False
History() = [11, 2, 1]
HistoryString() = "11, 2, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "11, 2, 1"
InformationStateString(1) = "11, 2, 1"
ObservationString(0) = "1 2 4 4"
ObservationString(1) = "1 2 4 4"
ObservationTensor(0): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 5, 6, 7, 10, 11, 14, 15]
StringLegalActions() = ["pile:1, take:1;", "pile:2, take:1;", "pile:3, take:1;", "pile:4, take:1;", "pile:2, take:2;", "pile:3, take:2;", "pile:4, take:2;", "pile:3, take:3;", "pile:4, take:3;", "pile:3, take:4;", "pile:4, take:4;"]

# Apply action "pile:4, take:2;"
action: 7

# State 4
# 1 2 4 2
IsTerminal() = False
History() = [11, 2, 1, 7]
HistoryString() = "11, 2, 1, 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "11, 2, 1, 7"
InformationStateString(1) = "11, 2, 1, 7"
ObservationString(0) = "1 2 4 2"
ObservationString(1) = "1 2 4 2"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 5, 6, 7, 10, 14]
StringLegalActions() = ["pile:1, take:1;", "pile:2, take:1;", "pile:3, take:1;", "pile:4, take:1;", "pile:2, take:2;", "pile:3, take:2;", "pile:4, take:2;", "pile:3, take:3;", "pile:3, take:4;"]

# Apply action "pile:2, take:1;"
action: 1

# State 5
# 1 1 4 2
IsTerminal() = False
History() = [11, 2, 1, 7, 1]
HistoryString() = "11, 2, 1, 7, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "11, 2, 1, 7, 1"
InformationStateString(1) = "11, 2, 1, 7, 1"
ObservationString(0) = "1 1 4 2"
ObservationString(1) = "1 1 4 2"
ObservationTensor(0): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 6, 7, 10, 14]
StringLegalActions() = ["pile:1, take:1;", "pile:2, take:1;", "pile:3, take:1;", "pile:4, take:1;", "pile:3, take:2;", "pile:4, take:2;", "pile:3, take:3;", "pile:3, take:4;"]

# Apply action "pile:1, take:1;"
action: 0

# State 6
# Apply action "pile:3, take:3;"
action: 10

# State 7
# Apply action "pile:3, take:1;"
action: 2

# State 8
# Apply action "pile:4, take:1;"
action: 3

# State 9
# Apply action "pile:4, take:1;"
action: 3

# State 10
# Apply action "pile:2, take:1;"
action: 1

# State 11
# 0 0 0 0
IsTerminal() = True
History() = [11, 2, 1, 7, 1, 0, 10, 2, 3, 3, 1]
HistoryString() = "11, 2, 1, 7, 1, 0, 10, 2, 3, 3, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "11, 2, 1, 7, 1, 0, 10, 2, 3, 3, 1"
InformationStateString(1) = "11, 2, 1, 7, 1, 0, 10, 2, 3, 3, 1"
ObservationString(0) = "0 0 0 0"
ObservationString(1) = "0 0 0 0"
ObservationTensor(0): ◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [-1, 1]
Returns() = [-1, 1]
