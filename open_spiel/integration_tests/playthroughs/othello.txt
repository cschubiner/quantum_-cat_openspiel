game: othello

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Othello"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = []
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "othello"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 65
PolicyTensorShape() = [65]
MaxChanceOutcomes() = 0
GetParameters() = {}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [3, 8, 8]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 192
MaxGameLength() = 64
ToString() = "othello()"

# State 0
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - - o x - - - 4
# 5 - - - x o - - - 5
# 6 - - - - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x o - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - x o - - - 4\n5 - - - o x - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [19, 26, 37, 44]
StringLegalActions() = ["d3 (x)", "c4 (x)", "f5 (x)", "e6 (x)"]

# Apply action "f5 (x)"
action: 37

# State 1
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - - o x - - - 4
# 5 - - - x x x - - 5
# 6 - - - - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37]
HistoryString() = "37"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37"
InformationStateString(1) = "37"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x x x - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - x o - - - 4\n5 - - - o o o - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [29, 43, 45]
StringLegalActions() = ["f4 (o)", "d6 (o)", "f6 (o)"]

# Apply action "f6 (o)"
action: 45

# State 2
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - - o x - - - 4
# 5 - - - x o x - - 5
# 6 - - - - - o - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45]
HistoryString() = "37 45"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45"
InformationStateString(1) = "37 45"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x o x - - 5\n6 - - - - - o - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - x o - - - 4\n5 - - - o x o - - 5\n6 - - - - - x - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [19, 26, 44, 53]
StringLegalActions() = ["d3 (x)", "c4 (x)", "e6 (x)", "f7 (x)"]

# Apply action "f7 (x)"
action: 53

# State 3
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - - o x - - - 4
# 5 - - - x o x - - 5
# 6 - - - - - x - - 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53]
HistoryString() = "37 45 53"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53"
InformationStateString(1) = "37 45 53"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x o x - - 5\n6 - - - - - x - - 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - x o - - - 4\n5 - - - o x o - - 5\n6 - - - - - o - - 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [20, 29, 34, 38, 43, 54]
StringLegalActions() = ["e3 (o)", "f4 (o)", "c5 (o)", "g5 (o)", "d6 (o)", "g7 (o)"]

# Apply action "e3 (o)"
action: 20

# State 4
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - o - - - 3
# 4 - - - o o - - - 4
# 5 - - - x o x - - 5
# 6 - - - - - x - - 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20]
HistoryString() = "37 45 53 20"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20"
InformationStateString(1) = "37 45 53 20"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - o - - - 3\n4 - - - o o - - - 4\n5 - - - x o x - - 5\n6 - - - - - x - - 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - x - - - 3\n4 - - - x x - - - 4\n5 - - - o x o - - 5\n6 - - - - - o - - 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 19, 21]
StringLegalActions() = ["c3 (x)", "d3 (x)", "f3 (x)"]

# Apply action "d3 (x)"
action: 19

# State 5
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x o - - - 3
# 4 - - - x x - - - 4
# 5 - - - x o x - - 5
# 6 - - - - - x - - 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19]
HistoryString() = "37 45 53 20 19"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19"
InformationStateString(1) = "37 45 53 20 19"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x o - - - 3\n4 - - - x x - - - 4\n5 - - - x o x - - 5\n6 - - - - - x - - 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o x - - - 3\n4 - - - o o - - - 4\n5 - - - o x o - - 5\n6 - - - - - o - - 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 34, 38, 54]
StringLegalActions() = ["c3 (o)", "c5 (o)", "g5 (o)", "g7 (o)"]

# Apply action "g5 (o)"
action: 38

# State 6
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x o - - - 3
# 4 - - - x x - - - 4
# 5 - - - x o o o - 5
# 6 - - - - - x - - 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38]
HistoryString() = "37 45 53 20 19 38"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38"
InformationStateString(1) = "37 45 53 20 19 38"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x o - - - 3\n4 - - - x x - - - 4\n5 - - - x o o o - 5\n6 - - - - - x - - 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o x - - - 3\n4 - - - o o - - - 4\n5 - - - o x x x - 5\n6 - - - - - o - - 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◉◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◉◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [12, 13, 21, 29, 31, 39, 44, 46]
StringLegalActions() = ["e2 (x)", "f2 (x)", "f3 (x)", "f4 (x)", "h4 (x)", "h5 (x)", "e6 (x)", "g6 (x)"]

# Apply action "f4 (x)"
action: 29

# State 7
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x o - - - 3
# 4 - - - x x x - - 4
# 5 - - - x o x o - 5
# 6 - - - - - x - - 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29]
HistoryString() = "37 45 53 20 19 38 29"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29"
InformationStateString(1) = "37 45 53 20 19 38 29"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x o - - - 3\n4 - - - x x x - - 4\n5 - - - x o x o - 5\n6 - - - - - x - - 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o x - - - 3\n4 - - - o o o - - 4\n5 - - - o x o x - 5\n6 - - - - - o - - 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◉◯◯  ◯◯◯◯◉◯◉◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◯◉◯  ◯◯◯◉◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 22, 34, 52, 54]
StringLegalActions() = ["c3 (o)", "g3 (o)", "c5 (o)", "e7 (o)", "g7 (o)"]

# Apply action "c3 (o)"
action: 18

# State 8
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - o o o - - - 3
# 4 - - - o x x - - 4
# 5 - - - x o x o - 5
# 6 - - - - - x - - 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18]
HistoryString() = "37 45 53 20 19 38 29 18"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18"
InformationStateString(1) = "37 45 53 20 19 38 29 18"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - o o o - - - 3\n4 - - - o x x - - 4\n5 - - - x o x o - 5\n6 - - - - - x - - 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - x x x - - - 3\n4 - - - x o o - - 4\n5 - - - o x o x - 5\n6 - - - - - o - - 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◉◯◯  ◯◯◯◯◉◯◉◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◯◉◯  ◯◯◯◉◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [9, 10, 11, 12, 26, 31, 39, 43, 44, 47]
StringLegalActions() = ["b2 (x)", "c2 (x)", "d2 (x)", "e2 (x)", "c4 (x)", "h4 (x)", "h5 (x)", "d6 (x)", "e6 (x)", "h6 (x)"]

# Apply action "h6 (x)"
action: 47

# State 9
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - o o o - - - 3
# 4 - - - o x x - - 4
# 5 - - - x o x x - 5
# 6 - - - - - x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47]
HistoryString() = "37 45 53 20 19 38 29 18 47"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - o o o - - - 3\n4 - - - o x x - - 4\n5 - - - x o x x - 5\n6 - - - - - x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - x x x - - - 3\n4 - - - x o o - - 4\n5 - - - o x o o - 5\n6 - - - - - o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◉◉◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◉◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [22, 30, 34, 39, 43, 46, 54]
StringLegalActions() = ["g3 (o)", "g4 (o)", "c5 (o)", "h5 (o)", "d6 (o)", "g6 (o)", "g7 (o)"]

# Apply action "g4 (o)"
action: 30

# State 10
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - o o o - - - 3
# 4 - - - o o o o - 4
# 5 - - - x o x x - 5
# 6 - - - - - x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30]
HistoryString() = "37 45 53 20 19 38 29 18 47 30"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - o o o - - - 3\n4 - - - o o o o - 4\n5 - - - x o x x - 5\n6 - - - - - x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - x x x - - - 3\n4 - - - x x x x - 4\n5 - - - o x o o - 5\n6 - - - - - o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◉◉◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◉◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [9, 10, 11, 21, 22, 23]
StringLegalActions() = ["b2 (x)", "c2 (x)", "d2 (x)", "f3 (x)", "g3 (x)", "h3 (x)"]

# Apply action "b2 (x)"
action: 9

# State 11
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x - - - - - - 2
# 3 - - x o o - - - 3
# 4 - - - x o o o - 4
# 5 - - - x x x x - 5
# 6 - - - - - x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x - - - - - - 2\n3 - - x o o - - - 3\n4 - - - x o o o - 4\n5 - - - x x x x - 5\n6 - - - - - x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o - - - - - - 2\n3 - - o x x - - - 3\n4 - - - o x x x - 4\n5 - - - o o o o - 5\n6 - - - - - o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◉◉◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◉◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [17, 26, 34, 42, 43, 44, 46, 61]
StringLegalActions() = ["b3 (o)", "c4 (o)", "c5 (o)", "c6 (o)", "d6 (o)", "e6 (o)", "g6 (o)", "f8 (o)"]

# Apply action "c4 (o)"
action: 26

# State 12
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x - - - - - - 2
# 3 - - x o o - - - 3
# 4 - - o o o o o - 4
# 5 - - - x x x x - 5
# 6 - - - - - x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x - - - - - - 2\n3 - - x o o - - - 3\n4 - - o o o o o - 4\n5 - - - x x x x - 5\n6 - - - - - x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o - - - - - - 2\n3 - - o x x - - - 3\n4 - - x x x x x - 4\n5 - - - o o o o - 5\n6 - - - - - o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◉◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [10, 11, 12, 17, 21, 22, 23, 34]
StringLegalActions() = ["c2 (x)", "d2 (x)", "e2 (x)", "b3 (x)", "f3 (x)", "g3 (x)", "h3 (x)", "c5 (x)"]

# Apply action "f3 (x)"
action: 21

# State 13
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x - - - - - - 2
# 3 - - x x x x - - 3
# 4 - - o o x x o - 4
# 5 - - - x x x x - 5
# 6 - - - - - x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x - - - - - - 2\n3 - - x x x x - - 3\n4 - - o o x x o - 4\n5 - - - x x x x - 5\n6 - - - - - x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o - - - - - - 2\n3 - - o o o o - - 3\n4 - - x x o o x - 4\n5 - - - o o o o - 5\n6 - - - - - o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◉◉◯◯◉◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◉◯◯◯◯◯◉  ◯◯◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 10, 11, 12, 13, 43, 44, 46, 54]
StringLegalActions() = ["a1 (o)", "c2 (o)", "d2 (o)", "e2 (o)", "f2 (o)", "d6 (o)", "e6 (o)", "g6 (o)", "g7 (o)"]

# Apply action "f2 (o)"
action: 13

# State 14
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x - - - o - - 2
# 3 - - x x o x - - 3
# 4 - - o o x x o - 4
# 5 - - - x x x x - 5
# 6 - - - - - x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x - - - o - - 2\n3 - - x x o x - - 3\n4 - - o o x x o - 4\n5 - - - x x x x - 5\n6 - - - - - x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o - - - x - - 2\n3 - - o o x o - - 3\n4 - - x x o o x - 4\n5 - - - o o o o - 5\n6 - - - - - o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◉◉◯◯◉◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◉◉◯◉◯◯
◉◉◯◯◯◯◯◉  ◯◯◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 11, 12, 17, 22, 23, 25, 31, 33, 34, 39]
StringLegalActions() = ["f1 (x)", "d2 (x)", "e2 (x)", "b3 (x)", "g3 (x)", "h3 (x)", "b4 (x)", "h4 (x)", "b5 (x)", "c5 (x)", "h5 (x)"]

# Apply action "b4 (x)"
action: 25

# State 15
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x - - - o - - 2
# 3 - - x x o x - - 3
# 4 - x x x x x o - 4
# 5 - - - x x x x - 5
# 6 - - - - - x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x - - - o - - 2\n3 - - x x o x - - 3\n4 - x x x x x o - 4\n5 - - - x x x x - 5\n6 - - - - - x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o - - - x - - 2\n3 - - o o x o - - 3\n4 - o o o o o x - 4\n5 - - - o o o o - 5\n6 - - - - - o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◉◉◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◯◯◉◯  ◯◉◉◉◉◉◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◉◉◉◉◉◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [12, 17, 22, 24, 34, 44, 46, 61]
StringLegalActions() = ["e2 (o)", "b3 (o)", "g3 (o)", "a4 (o)", "c5 (o)", "e6 (o)", "g6 (o)", "f8 (o)"]

# Apply action "e6 (o)"
action: 44

# State 16
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x - - - o - - 2
# 3 - - x x o x - - 3
# 4 - x x x o x o - 4
# 5 - - - x o o x - 5
# 6 - - - - o x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x - - - o - - 2\n3 - - x x o x - - 3\n4 - x x x o x o - 4\n5 - - - x o o x - 5\n6 - - - - o x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o - - - x - - 2\n3 - - o o x o - - 3\n4 - o o o x o x - 4\n5 - - - o x x o - 5\n6 - - - - x o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◯◉◯◯  ◯◯◯◯◉◯◉◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◉◉◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◉◯◉◯  ◯◉◉◉◯◉◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 6, 11, 22, 31, 39, 43, 46]
StringLegalActions() = ["f1 (x)", "g1 (x)", "d2 (x)", "g3 (x)", "h4 (x)", "h5 (x)", "d6 (x)", "g6 (x)"]

# Apply action "h4 (x)"
action: 31

# State 17
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x - - - o - - 2
# 3 - - x x o x - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x - - - o - - 2\n3 - - x x o x - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o - - - x - - 2\n3 - - o o x o - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◉◉◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 10, 14, 17, 22, 23, 24, 34, 39, 42, 46, 54, 61, 62]
StringLegalActions() = ["a1 (o)", "c2 (o)", "g2 (o)", "b3 (o)", "g3 (o)", "h3 (o)", "a4 (o)", "c5 (o)", "h5 (o)", "c6 (o)", "g6 (o)", "g7 (o)", "f8 (o)", "g8 (o)"]

# Apply action "c2 (o)"
action: 10

# State 18
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x o - - o - - 2
# 3 - - x o o x - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x o - - o - - 2\n3 - - x o o x - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o x - - x - - 2\n3 - - o x x o - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◉◯◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◯◯◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◯◉◯◯  ◯◯◯◉◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◉◯◉◉  ◯◯◉◯◯◉◯◯  ◯◉◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 5, 6, 11, 12, 43, 51]
StringLegalActions() = ["c1 (x)", "f1 (x)", "g1 (x)", "d2 (x)", "e2 (x)", "d6 (x)", "d7 (x)"]

# Apply action "e2 (x)"
action: 12

# State 19
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x o - x o - - 2
# 3 - - x x o x - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x o - x o - - 2\n3 - - x x o x - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o x - o x - - 2\n3 - - o o x o - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◯◯◉◉  ◯◉◯◯◉◯◯◯  ◯◯◉◯◯◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◯◯◉◉  ◯◯◉◯◯◉◯◯  ◯◉◯◯◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◯◯◉◉◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 4, 8, 11, 14, 17, 22, 23, 24, 34, 39, 42, 46, 54, 61, 62]
StringLegalActions() = ["a1 (o)", "e1 (o)", "a2 (o)", "d2 (o)", "g2 (o)", "b3 (o)", "g3 (o)", "h3 (o)", "a4 (o)", "c5 (o)", "h5 (o)", "c6 (o)", "g6 (o)", "g7 (o)", "f8 (o)", "g8 (o)"]

# Apply action "g2 (o)"
action: 14

# State 20
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - x o - x o o - 2
# 3 - - x x o o - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - x o - x o o - 2\n3 - - x x o o - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - o x - o x x - 2\n3 - - o o x x - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◯◯◯◉  ◯◉◯◯◉◯◯◯  ◯◯◉◯◯◉◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◯◯◯◉  ◯◯◉◯◯◉◉◯  ◯◉◯◯◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◯◯◉◉◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 5, 6, 7, 11, 15, 22, 43, 46, 51, 52]
StringLegalActions() = ["b1 (x)", "c1 (x)", "f1 (x)", "g1 (x)", "h1 (x)", "d2 (x)", "h2 (x)", "g3 (x)", "d6 (x)", "g6 (x)", "d7 (x)", "e7 (x)"]

# Apply action "g1 (x)"
action: 6

# State 21
#   a b c d e f g h
# 1 - - - - - - x - 1
# 2 - x o - x x o - 2
# 3 - - x x x o - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o x - x 6
# 7 - - - - - x - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - x - 1\n2 - x o - x x o - 2\n3 - - x x x o - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o x - x 6\n7 - - - - - x - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - o - 1\n2 - o x - o o x - 2\n3 - - o o o x - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x o - o 6\n7 - - - - - o - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◯◯◯◉  ◯◉◯◯◉◉◯◯  ◯◯◉◯◯◯◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◉◯◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯
◉◯◯◉◯◯◯◉  ◯◯◉◯◯◯◉◯  ◯◉◯◯◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◉◯◉
◉◉◉◉◉◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 4, 5, 8, 11, 17, 22, 23, 24, 34, 39, 42, 46, 54, 61, 62]
StringLegalActions() = ["a1 (o)", "d1 (o)", "e1 (o)", "f1 (o)", "a2 (o)", "d2 (o)", "b3 (o)", "g3 (o)", "h3 (o)", "a4 (o)", "c5 (o)", "h5 (o)", "c6 (o)", "g6 (o)", "g7 (o)", "f8 (o)", "g8 (o)"]

# Apply action "g7 (o)"
action: 54

# State 22
#   a b c d e f g h
# 1 - - - - - - x - 1
# 2 - x o - x x o - 2
# 3 - - x x x o - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o o - x 6
# 7 - - - - - x o - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - x - 1\n2 - x o - x x o - 2\n3 - - x x x o - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o o - x 6\n7 - - - - - x o - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - o - 1\n2 - o x - o o x - 2\n3 - - o o o x - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x x - o 6\n7 - - - - - o x - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◯◯◯◉  ◯◉◯◯◉◉◯◯  ◯◯◉◯◯◯◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◉◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯
◉◯◯◉◯◯◯◉  ◯◯◉◯◯◯◉◯  ◯◉◯◯◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 7, 11, 15, 22, 43, 46, 51, 52, 55, 61, 63]
StringLegalActions() = ["b1 (x)", "c1 (x)", "h1 (x)", "d2 (x)", "h2 (x)", "g3 (x)", "d6 (x)", "g6 (x)", "d7 (x)", "e7 (x)", "h7 (x)", "f8 (x)", "h8 (x)"]

# Apply action "h7 (x)"
action: 55

# State 23
#   a b c d e f g h
# 1 - - - - - - x - 1
# 2 - x o - x x o - 2
# 3 - - x x x o - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o o - x 6
# 7 - - - - - x x x 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - x - 1\n2 - x o - x x o - 2\n3 - - x x x o - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o o - x 6\n7 - - - - - x x x 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - o - 1\n2 - o x - o o x - 2\n3 - - o o o x - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x x - o 6\n7 - - - - - o o o 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯
◉◯◯◉◯◯◯◉  ◯◉◯◯◉◉◯◯  ◯◯◉◯◯◯◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯
◉◯◯◉◯◯◯◉  ◯◯◉◯◯◯◉◯  ◯◉◯◯◉◉◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◉
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 4, 5, 8, 11, 17, 22, 23, 24, 34, 39, 42, 61, 62, 63]
StringLegalActions() = ["a1 (o)", "d1 (o)", "e1 (o)", "f1 (o)", "a2 (o)", "d2 (o)", "b3 (o)", "g3 (o)", "h3 (o)", "a4 (o)", "c5 (o)", "h5 (o)", "c6 (o)", "f8 (o)", "g8 (o)", "h8 (o)"]

# Apply action "f1 (o)"
action: 5

# State 24
#   a b c d e f g h
# 1 - - - - - o x - 1
# 2 - x o - x o o - 2
# 3 - - x x x o - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o o - x 6
# 7 - - - - - x x x 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - o x - 1\n2 - x o - x o o - 2\n3 - - x x x o - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o o - x 6\n7 - - - - - x x x 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - x o - 1\n2 - o x - o x x - 2\n3 - - o o o x - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x x - o 6\n7 - - - - - o o o 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◯◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◉◯◯◯◉  ◯◉◯◯◉◯◯◯  ◯◯◉◯◯◉◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◉◯
◉◯◯◉◯◯◯◉  ◯◯◉◯◯◉◉◯  ◯◉◯◯◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◉
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 4, 7, 11, 15, 22, 43, 46, 51, 52]
StringLegalActions() = ["b1 (x)", "c1 (x)", "e1 (x)", "h1 (x)", "d2 (x)", "h2 (x)", "g3 (x)", "d6 (x)", "g6 (x)", "d7 (x)", "e7 (x)"]

# Apply action "b1 (x)"
action: 1

# State 25
#   a b c d e f g h
# 1 - x - - - o x - 1
# 2 - x x - x o o - 2
# 3 - - x x x o - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o o - x 6
# 7 - - - - - x x x 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1"
ObservationString(0) = "  a b c d e f g h  \n1 - x - - - o x - 1\n2 - x x - x o o - 2\n3 - - x x x o - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o o - x 6\n7 - - - - - x x x 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - - - x o - 1\n2 - o o - o x x - 2\n3 - - o o o x - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x x - o 6\n7 - - - - - o o o 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◉◉◯◯◉  ◯◉◯◯◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◉◯◯◯◉  ◯◉◉◯◉◯◯◯  ◯◯◯◯◯◉◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◉◉◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◉◯
◉◯◯◉◯◯◯◉  ◯◯◯◯◯◉◉◯  ◯◉◉◯◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◉
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 4, 7, 11, 17, 22, 23, 24, 33, 34, 39, 42, 61, 62, 63]
StringLegalActions() = ["a1 (o)", "d1 (o)", "e1 (o)", "h1 (o)", "d2 (o)", "b3 (o)", "g3 (o)", "h3 (o)", "a4 (o)", "b5 (o)", "c5 (o)", "h5 (o)", "c6 (o)", "f8 (o)", "g8 (o)", "h8 (o)"]

# Apply action "d2 (o)"
action: 11

# State 26
#   a b c d e f g h
# 1 - x - - - o x - 1
# 2 - x x o o o o - 2
# 3 - - x x x o - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o o - x 6
# 7 - - - - - x x x 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11"
ObservationString(0) = "  a b c d e f g h  \n1 - x - - - o x - 1\n2 - x x o o o o - 2\n3 - - x x x o - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o o - x 6\n7 - - - - - x x x 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - - - x o - 1\n2 - o o x x x x - 2\n3 - - o o o x - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x x - o 6\n7 - - - - - o o o 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◉◉◯◯◉  ◯◉◯◯◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◉◉◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◉◯◯◯◯◉◯
◉◯◯◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◯◉◉◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◉
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 3, 4, 7, 15, 22, 43, 46, 51, 52]
StringLegalActions() = ["c1 (x)", "d1 (x)", "e1 (x)", "h1 (x)", "h2 (x)", "g3 (x)", "d6 (x)", "g6 (x)", "d7 (x)", "e7 (x)"]

# Apply action "d1 (x)"
action: 3

# State 27
#   a b c d e f g h
# 1 - x - x - o x - 1
# 2 - x x x x o o - 2
# 3 - - x x x x - - 3
# 4 - x x x o x x x 4
# 5 - - - x o o x - 5
# 6 - - - - o o - x 6
# 7 - - - - - x x x 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x - 1\n2 - x x x x o o - 2\n3 - - x x x x - - 3\n4 - x x x o x x x 4\n5 - - - x o o x - 5\n6 - - - - o o - x 6\n7 - - - - - x x x 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o - 1\n2 - o o o o x x - 2\n3 - - o o o o - - 3\n4 - o o o x o o o 4\n5 - - - o x x o - 5\n6 - - - - x x - o 6\n7 - - - - - o o o 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◉  ◯◉◯◉◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◉◯◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◉
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 4, 7, 8, 17, 22, 23, 24, 33, 34, 39, 42, 61, 62, 63]
StringLegalActions() = ["a1 (o)", "e1 (o)", "h1 (o)", "a2 (o)", "b3 (o)", "g3 (o)", "h3 (o)", "a4 (o)", "b5 (o)", "c5 (o)", "h5 (o)", "c6 (o)", "f8 (o)", "g8 (o)", "h8 (o)"]

# Apply action "h3 (o)"
action: 23

# State 28
#   a b c d e f g h
# 1 - x - x - o x - 1
# 2 - x x x x o o - 2
# 3 - - x x x x - o 3
# 4 - x x x o x o x 4
# 5 - - - x o o x - 5
# 6 - - - - o o - x 6
# 7 - - - - - x x x 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x - 1\n2 - x x x x o o - 2\n3 - - x x x x - o 3\n4 - x x x o x o x 4\n5 - - - x o o x - 5\n6 - - - - o o - x 6\n7 - - - - - x x x 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o - 1\n2 - o o o o x x - 2\n3 - - o o o o - x 3\n4 - o o o x o x o 4\n5 - - - o x x o - 5\n6 - - - - x x - o 6\n7 - - - - - o o o 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◉  ◯◉◯◉◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◉◉◯◯◯◯◉◯  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◯◉  ◯◯◯◯◉◯◉◯
◉◉◉◯◯◯◯◉  ◯◯◯◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◉◯◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◉◉◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◉◯  ◯◉◉◉◯◉◯◉
◉◉◉◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◉
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 7, 15, 22, 39, 43, 46, 52]
StringLegalActions() = ["e1 (x)", "h1 (x)", "h2 (x)", "g3 (x)", "h5 (x)", "d6 (x)", "g6 (x)", "e7 (x)"]

# Apply action "h5 (x)"
action: 39

# State 29
#   a b c d e f g h
# 1 - x - x - o x - 1
# 2 - x x x x o o - 2
# 3 - - x x x x - o 3
# 4 - x x x o x x x 4
# 5 - - - x o o x x 5
# 6 - - - - o o - x 6
# 7 - - - - - x x x 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x - 1\n2 - x x x x o o - 2\n3 - - x x x x - o 3\n4 - x x x o x x x 4\n5 - - - x o o x x 5\n6 - - - - o o - x 6\n7 - - - - - x x x 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o - 1\n2 - o o o o x x - 2\n3 - - o o o o - x 3\n4 - o o o x o o o 4\n5 - - - o x x o o 5\n6 - - - - x x - o 6\n7 - - - - - o o o 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◉  ◯◉◯◉◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◉◉◯◯◯◯◉◯  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◯◯◉◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◉◯◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◉◉◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◉
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◉
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 4, 7, 8, 17, 22, 24, 33, 34, 42, 61, 62, 63]
StringLegalActions() = ["a1 (o)", "e1 (o)", "h1 (o)", "a2 (o)", "b3 (o)", "g3 (o)", "a4 (o)", "b5 (o)", "c5 (o)", "c6 (o)", "f8 (o)", "g8 (o)", "h8 (o)"]

# Apply action "g8 (o)"
action: 62

# State 30
#   a b c d e f g h
# 1 - x - x - o x - 1
# 2 - x x x x o o - 2
# 3 - - x x x x - o 3
# 4 - x x x o x x x 4
# 5 - - - x o o x x 5
# 6 - - - - o o - x 6
# 7 - - - - - o x x 7
# 8 - - - - - - o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x - 1\n2 - x x x x o o - 2\n3 - - x x x x - o 3\n4 - x x x o x x x 4\n5 - - - x o o x x 5\n6 - - - - o o - x 6\n7 - - - - - o x x 7\n8 - - - - - - o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o - 1\n2 - o o o o x x - 2\n3 - - o o o o - x 3\n4 - o o o x o o o 4\n5 - - - o x x o o 5\n6 - - - - x x - o 6\n7 - - - - - x o o 7\n8 - - - - - - x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◉  ◯◉◯◉◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◉◉◯◯◯◯◉◯  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◉◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◯◯◉◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯
ObservationTensor(1):
◉◯◉◯◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◉◉◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◉◉◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◉◉◯◯  ◯◯◯◉◯◯◉◉
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◉◉
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 7, 15, 22, 43, 46, 51, 52, 61]
StringLegalActions() = ["e1 (x)", "h1 (x)", "h2 (x)", "g3 (x)", "d6 (x)", "g6 (x)", "d7 (x)", "e7 (x)", "f8 (x)"]

# Apply action "e7 (x)"
action: 52

# State 31
#   a b c d e f g h
# 1 - x - x - o x - 1
# 2 - x x x x o o - 2
# 3 - - x x x x - o 3
# 4 - x x x x x x x 4
# 5 - - - x x o x x 5
# 6 - - - - x x - x 6
# 7 - - - - x x x x 7
# 8 - - - - - - o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x - 1\n2 - x x x x o o - 2\n3 - - x x x x - o 3\n4 - x x x x x x x 4\n5 - - - x x o x x 5\n6 - - - - x x - x 6\n7 - - - - x x x x 7\n8 - - - - - - o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o - 1\n2 - o o o o x x - 2\n3 - - o o o o - x 3\n4 - o o o o o o o 4\n5 - - - o o x o o 5\n6 - - - - o o - o 6\n7 - - - - o o o o 7\n8 - - - - - - x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◉  ◯◉◯◉◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◉◉◯◯◯◯◉◯  ◯◯◉◉◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◉◉  ◯◯◯◯◯◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯
ObservationTensor(1):
◉◯◉◯◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◉◉◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◯◯◯◉◉◯◉◉
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◯◉
◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◉◉
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [7, 8, 17, 33, 34, 42, 46, 51, 61, 63]
StringLegalActions() = ["h1 (o)", "a2 (o)", "b3 (o)", "b5 (o)", "c5 (o)", "c6 (o)", "g6 (o)", "d7 (o)", "f8 (o)", "h8 (o)"]

# Apply action "b5 (o)"
action: 33

# State 32
#   a b c d e f g h
# 1 - x - x - o x - 1
# 2 - x x x o o o - 2
# 3 - - x o x x - o 3
# 4 - x o x x x x x 4
# 5 - o - x x o x x 5
# 6 - - - - x x - x 6
# 7 - - - - x x x x 7
# 8 - - - - - - o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x - 1\n2 - x x x o o o - 2\n3 - - x o x x - o 3\n4 - x o x x x x x 4\n5 - o - x x o x x 5\n6 - - - - x x - x 6\n7 - - - - x x x x 7\n8 - - - - - - o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o - 1\n2 - o o o x x x - 2\n3 - - o x o o - x 3\n4 - o x o o o o o 4\n5 - x - o o x o o 5\n6 - - - - o o - o 6\n7 - - - - o o o o 7\n8 - - - - - - x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◉  ◯◉◯◉◯◯◉◯  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◯
◉◉◯◯◯◯◉◯  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◉◯◯◯◯◯  ◯◯◯◉◉◯◉◉  ◯◉◯◯◯◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯
ObservationTensor(1):
◉◯◉◯◉◯◯◉  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◉◉◉◯  ◯◉◉◉◯◯◯◯
◉◉◯◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◯◉◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◉
◉◯◉◯◯◯◯◯  ◯◉◯◯◯◉◯◯  ◯◯◯◉◉◯◉◉
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◯◉
◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◉◉
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 7, 15, 17, 22, 34, 41, 46]
StringLegalActions() = ["e1 (x)", "h1 (x)", "h2 (x)", "b3 (x)", "g3 (x)", "c5 (x)", "b6 (x)", "g6 (x)"]

# Apply action "h1 (x)"
action: 7

# State 33
#   a b c d e f g h
# 1 - x - x - o x x 1
# 2 - x x x o o x - 2
# 3 - - x o x x - o 3
# 4 - x o x x x x x 4
# 5 - o - x x o x x 5
# 6 - - - - x x - x 6
# 7 - - - - x x x x 7
# 8 - - - - - - o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x x 1\n2 - x x x o o x - 2\n3 - - x o x x - o 3\n4 - x o x x x x x 4\n5 - o - x x o x x 5\n6 - - - - x x - x 6\n7 - - - - x x x x 7\n8 - - - - - - o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o o 1\n2 - o o o x x o - 2\n3 - - o x o o - x 3\n4 - o x o o o o o 4\n5 - x - o o x o o 5\n6 - - - - o o - o 6\n7 - - - - o o o o 7\n8 - - - - - - x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◯  ◯◉◯◉◯◯◉◉  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◯◯◯◯◉◯  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◉◯◯◯◯◯  ◯◯◯◉◉◯◉◉  ◯◉◯◯◯◉◯◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯
ObservationTensor(1):
◉◯◉◯◉◯◯◯  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◉
◉◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◉◯
◉◉◯◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◯◉◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◉
◉◯◉◯◯◯◯◯  ◯◉◯◯◯◉◯◯  ◯◯◯◉◉◯◉◉
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◯◉
◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◉◉
◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 8, 15, 17, 22, 24, 34, 43, 46, 51, 60, 61, 63]
StringLegalActions() = ["c1 (o)", "a2 (o)", "h2 (o)", "b3 (o)", "g3 (o)", "a4 (o)", "c5 (o)", "d6 (o)", "g6 (o)", "d7 (o)", "e8 (o)", "f8 (o)", "h8 (o)"]

# Apply action "h8 (o)"
action: 63

# State 34
#   a b c d e f g h
# 1 - x - x - o x x 1
# 2 - x x x o o x - 2
# 3 - - x o x x - o 3
# 4 - x o x x x x o 4
# 5 - o - x x o x o 5
# 6 - - - - x x - o 6
# 7 - - - - x x x o 7
# 8 - - - - - - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x x 1\n2 - x x x o o x - 2\n3 - - x o x x - o 3\n4 - x o x x x x o 4\n5 - o - x x o x o 5\n6 - - - - x x - o 6\n7 - - - - x x x o 7\n8 - - - - - - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o o 1\n2 - o o o x x o - 2\n3 - - o x o o - x 3\n4 - o x o o o o x 4\n5 - x - o o x o x 5\n6 - - - - o o - x 6\n7 - - - - o o o x 7\n8 - - - - - - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◯  ◯◉◯◉◯◯◉◉  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◯◯◯◯◉◯  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◯◯◉◉◯◉◯  ◯◉◯◯◯◉◯◉
◉◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◉◯◉◯◉◯◯◯  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◉
◉◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◉◯
◉◉◯◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◯◉◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◉◯◯◯◉◯◉  ◯◯◯◉◉◯◉◯
◉◉◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◉◯
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 17, 34, 41, 46]
StringLegalActions() = ["e1 (x)", "b3 (x)", "c5 (x)", "b6 (x)", "g6 (x)"]

# Apply action "b6 (x)"
action: 41

# State 35
#   a b c d e f g h
# 1 - x - x - o x x 1
# 2 - x x x o o x - 2
# 3 - - x o x x - o 3
# 4 - x o x x x x o 4
# 5 - x - x x o x o 5
# 6 - x - - x x - o 6
# 7 - - - - x x x o 7
# 8 - - - - - - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x x 1\n2 - x x x o o x - 2\n3 - - x o x x - o 3\n4 - x o x x x x o 4\n5 - x - x x o x o 5\n6 - x - - x x - o 6\n7 - - - - x x x o 7\n8 - - - - - - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o o 1\n2 - o o o x x o - 2\n3 - - o x o o - x 3\n4 - o x o o o o x 4\n5 - o - o o x o x 5\n6 - o - - o o - x 6\n7 - - - - o o o x 7\n8 - - - - - - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◯  ◯◉◯◉◯◯◉◉  ◯◯◯◯◯◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯
◉◉◯◯◯◯◉◯  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◉◯◉◯◉◯◯◯  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◉
◉◯◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯  ◯◉◉◉◯◯◉◯
◉◉◯◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◯◉◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◉◯◯◉◉◯◯
◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◉◯
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 8, 15, 17, 22, 24, 34, 40, 43, 46, 51, 59, 60, 61]
StringLegalActions() = ["a1 (o)", "c1 (o)", "a2 (o)", "h2 (o)", "b3 (o)", "g3 (o)", "a4 (o)", "c5 (o)", "a6 (o)", "d6 (o)", "g6 (o)", "d7 (o)", "d8 (o)", "e8 (o)", "f8 (o)"]

# Apply action "a2 (o)"
action: 8

# State 36
#   a b c d e f g h
# 1 - x - x - o x x 1
# 2 o o o o o o x - 2
# 3 - - x o x x - o 3
# 4 - x o x x x x o 4
# 5 - x - x x o x o 5
# 6 - x - - x x - o 6
# 7 - - - - x x x o 7
# 8 - - - - - - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8"
ObservationString(0) = "  a b c d e f g h  \n1 - x - x - o x x 1\n2 o o o o o o x - 2\n3 - - x o x x - o 3\n4 - x o x x x x o 4\n5 - x - x x o x o 5\n6 - x - - x x - o 6\n7 - - - - x x x o 7\n8 - - - - - - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - o - o - x o o 1\n2 x x x x x x o - 2\n3 - - o x o o - x 3\n4 - o x o o o o x 4\n5 - o - o o x o x 5\n6 - o - - o o - x 6\n7 - - - - o o o x 7\n8 - - - - - - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◉◯◉◯◯◯  ◯◉◯◉◯◯◉◉  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◉◯  ◉◉◉◉◉◉◯◯
◉◉◯◯◯◯◉◯  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◉◯◉◯◉◯◯◯  ◯◯◯◯◯◉◯◯  ◯◉◯◉◯◯◉◉
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◯
◉◉◯◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◯◉◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◉◯◯◉◉◯◯
◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◉◯
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 4, 17, 34, 46]
StringLegalActions() = ["a1 (x)", "c1 (x)", "e1 (x)", "b3 (x)", "c5 (x)", "g6 (x)"]

# Apply action "a1 (x)"
action: 0

# State 37
#   a b c d e f g h
# 1 x x - x - o x x 1
# 2 o x o o o o x - 2
# 3 - - x o x x - o 3
# 4 - x o x x x x o 4
# 5 - x - x x o x o 5
# 6 - x - - x x - o 6
# 7 - - - - x x x o 7
# 8 - - - - - - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x - o x x 1\n2 o x o o o o x - 2\n3 - - x o x x - o 3\n4 - x o x x x x o 4\n5 - x - x x o x o 5\n6 - x - - x x - o 6\n7 - - - - x x x o 7\n8 - - - - - - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o - x o o 1\n2 x o x x x x o - 2\n3 - - o x o o - x 3\n4 - o x o o o o x 4\n5 - o - o o x o x 5\n6 - o - - o o - x 6\n7 - - - - o o o x 7\n8 - - - - - - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◉◯◯◯  ◉◉◯◉◯◯◉◉  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◉◯  ◉◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◯  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◉◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◯◉◯◯◉◉
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◯◯  ◯◉◯◯◯◯◉◯
◉◉◯◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◯◉◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◉◯◯◉◉◯◯
◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◉  ◯◯◯◯◉◉◉◯
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [15, 17, 22, 24, 32, 34, 40, 43, 46, 51, 59, 60, 61]
StringLegalActions() = ["h2 (o)", "b3 (o)", "g3 (o)", "a4 (o)", "a5 (o)", "c5 (o)", "a6 (o)", "d6 (o)", "g6 (o)", "d7 (o)", "d8 (o)", "e8 (o)", "f8 (o)"]

# Apply action "d7 (o)"
action: 51

# State 38
#   a b c d e f g h
# 1 x x - x - o x x 1
# 2 o x o o o o x - 2
# 3 - - x o x x - o 3
# 4 - x o x x x x o 4
# 5 - x - x x o x o 5
# 6 - x - - o x - o 6
# 7 - - - o o o o o 7
# 8 - - - - - - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x - o x x 1\n2 o x o o o o x - 2\n3 - - x o x x - o 3\n4 - x o x x x x o 4\n5 - x - x x o x o 5\n6 - x - - o x - o 6\n7 - - - o o o o o 7\n8 - - - - - - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o - x o o 1\n2 x o x x x x o - 2\n3 - - o x o o - x 3\n4 - o x o o o o x 4\n5 - o - o o x o x 5\n6 - o - - x o - x 6\n7 - - - x x x x x 7\n8 - - - - - - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◉◯◯◯  ◉◉◯◉◯◯◉◉  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◯◯◯◉◯  ◉◯◉◉◉◉◯◯
◉◉◯◯◯◯◉◯  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◯◉◯◯  ◯◯◯◯◉◯◯◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◉◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◯◉◯◯◉◉
◯◯◯◯◯◯◯◉  ◉◯◉◉◉◉◯◯  ◯◉◯◯◯◯◉◯
◉◉◯◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◯◉◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◉◯◯◉  ◯◉◯◯◯◉◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 16, 17, 34, 43, 46, 58, 59, 60, 61]
StringLegalActions() = ["c1 (x)", "e1 (x)", "a3 (x)", "b3 (x)", "c5 (x)", "d6 (x)", "g6 (x)", "c8 (x)", "d8 (x)", "e8 (x)", "f8 (x)"]

# Apply action "e1 (x)"
action: 4

# State 39
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o x - 2
# 3 - - x o x x - o 3
# 4 - x o x x x x o 4
# 5 - x - x x o x o 5
# 6 - x - - o x - o 6
# 7 - - - o o o o o 7
# 8 - - - - - - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o x - 2\n3 - - x o x x - o 3\n4 - x o x x x x o 4\n5 - x - x x o x o 5\n6 - x - - o x - o 6\n7 - - - o o o o o 7\n8 - - - - - - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x o - 2\n3 - - o x o o - x 3\n4 - o x o o o o x 4\n5 - o - o o x o x 5\n6 - o - - x o - x 6\n7 - - - x x x x x 7\n8 - - - - - - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◉◉◯◉◯  ◉◯◉◯◯◉◯◯
◉◉◯◯◯◯◉◯  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◯◉◯◯  ◯◯◯◯◉◯◯◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◯◉◯◯◉◯◯  ◯◉◯◉◉◯◉◯
◉◉◯◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◯◉◯◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◉◯◯◉  ◯◉◯◯◯◉◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 15, 17, 22, 24, 34, 40, 43, 46]
StringLegalActions() = ["c1 (o)", "h2 (o)", "b3 (o)", "g3 (o)", "a4 (o)", "c5 (o)", "a6 (o)", "d6 (o)", "g6 (o)"]

# Apply action "g3 (o)"
action: 22

# State 40
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o x - 2
# 3 - - x o o o o o 3
# 4 - x o x x x x o 4
# 5 - x - x x o x o 5
# 6 - x - - o x - o 6
# 7 - - - o o o o o 7
# 8 - - - - - - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o x - 2\n3 - - x o o o o o 3\n4 - x o x x x x o 4\n5 - x - x x o x o 5\n6 - x - - o x - o 6\n7 - - - o o o o o 7\n8 - - - - - - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x o - 2\n3 - - o x x x x x 3\n4 - o x o o o o x 4\n5 - o - o o x o x 5\n6 - o - - x o - x 6\n7 - - - x x x x x 7\n8 - - - - - - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◉◉◯◉◯  ◉◯◉◯◯◉◯◯
◉◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◯◉◯◯  ◯◯◯◯◉◯◯◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◯◉◯◯◉◯◯  ◯◉◯◉◉◯◉◯
◉◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◉◯◯◉  ◯◉◯◯◯◉◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 15, 16, 17, 34, 43, 46, 58, 59, 60, 61]
StringLegalActions() = ["c1 (x)", "h2 (x)", "a3 (x)", "b3 (x)", "c5 (x)", "d6 (x)", "g6 (x)", "c8 (x)", "d8 (x)", "e8 (x)", "f8 (x)"]

# Apply action "e8 (x)"
action: 60

# State 41
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o x - 2
# 3 - - x o o o o o 3
# 4 - x o x x x x o 4
# 5 - x - x x o x o 5
# 6 - x - - x x - o 6
# 7 - - - o x o o o 7
# 8 - - - - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o x - 2\n3 - - x o o o o o 3\n4 - x o x x x x o 4\n5 - x - x x o x o 5\n6 - x - - x x - o 6\n7 - - - o x o o o 7\n8 - - - - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x o - 2\n3 - - o x x x x x 3\n4 - o x o o o o x 4\n5 - o - o o x o x 5\n6 - o - - o o - x 6\n7 - - - x o x x x 7\n8 - - - - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◉◯◉◉◯◉◯  ◉◯◉◯◯◉◯◯
◉◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◉◉
◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◯◉◯◯◉◯◯  ◯◉◯◉◉◯◉◯
◉◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◉◯◯◉◉◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 15, 17, 24, 34, 40, 42, 43, 46, 59]
StringLegalActions() = ["c1 (o)", "h2 (o)", "b3 (o)", "a4 (o)", "c5 (o)", "a6 (o)", "c6 (o)", "d6 (o)", "g6 (o)", "d8 (o)"]

# Apply action "h2 (o)"
action: 15

# State 42
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 - - x o o o o o 3
# 4 - x o x x x x o 4
# 5 - x - x x o x o 5
# 6 - x - - x x - o 6
# 7 - - - o x o o o 7
# 8 - - - - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 - - x o o o o o 3\n4 - x o x x x x o 4\n5 - x - x x o x o 5\n6 - x - - x x - o 6\n7 - - - o x o o o 7\n8 - - - - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 - - o x x x x x 3\n4 - o x o o o o x 4\n5 - o - o o x o x 5\n6 - o - - o o - x 6\n7 - - - x o x x x 7\n8 - - - - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◉◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯  ◯◯◉◯◯◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◉◉
◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◉◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◉  ◯◉◯◉◉◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◉◯◯◉◉◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 16, 17, 34, 42, 46, 50, 58, 61]
StringLegalActions() = ["c1 (x)", "a3 (x)", "b3 (x)", "c5 (x)", "c6 (x)", "g6 (x)", "c7 (x)", "c8 (x)", "f8 (x)"]

# Apply action "c5 (x)"
action: 34

# State 43
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 - - x o o o o o 3
# 4 - x x x x x x o 4
# 5 - x x x x o x o 5
# 6 - x - - x x - o 6
# 7 - - - o x o o o 7
# 8 - - - - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 - - x o o o o o 3\n4 - x x x x x x o 4\n5 - x x x x o x o 5\n6 - x - - x x - o 6\n7 - - - o x o o o 7\n8 - - - - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 - - o x x x x x 3\n4 - o o o o o o x 4\n5 - o o o o x o x 5\n6 - o - - o o - x 6\n7 - - - x o x x x 7\n8 - - - - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◉◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◉◉◉◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◉◉◉
◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◉◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◯◉◉◉◉◉◉◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◯◉◉◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◉◯◯◉◉◯◯
◉◉◉◯◯◯◯◯  ◯◯◯◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 17, 24, 32, 40, 42, 43, 46, 48, 59]
StringLegalActions() = ["c1 (o)", "b3 (o)", "a4 (o)", "a5 (o)", "a6 (o)", "c6 (o)", "d6 (o)", "g6 (o)", "a7 (o)", "d8 (o)"]

# Apply action "a7 (o)"
action: 48

# State 44
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 - - x o o o o o 3
# 4 - x x o x x x o 4
# 5 - x o x x o x o 5
# 6 - o - - x x - o 6
# 7 o - - o x o o o 7
# 8 - - - - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 - - x o o o o o 3\n4 - x x o x x x o 4\n5 - x o x x o x o 5\n6 - o - - x x - o 6\n7 o - - o x o o o 7\n8 - - - - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 - - o x x x x x 3\n4 - o o x o o o x 4\n5 - o x o o x o x 5\n6 - x - - o o - x 6\n7 x - - x o x x x 7\n8 - - - - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◉◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◉◉◯◉◉◉◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◉◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◯◯◯◉◉◯◯  ◯◉◯◯◯◯◯◉
◯◉◉◯◯◯◯◯  ◯◯◯◯◉◯◯◯  ◉◯◯◉◯◉◉◉
◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◉◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◉  ◯◉◉◯◉◉◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◉◯◯◯◯◯◉  ◯◯◯◯◉◉◯◯
◯◉◉◯◯◯◯◯  ◉◯◯◉◯◉◉◉  ◯◯◯◯◉◯◯◯
◉◉◉◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 16, 17, 42, 43, 46, 49, 50, 58, 61]
StringLegalActions() = ["c1 (x)", "a3 (x)", "b3 (x)", "c6 (x)", "d6 (x)", "g6 (x)", "b7 (x)", "c7 (x)", "c8 (x)", "f8 (x)"]

# Apply action "b7 (x)"
action: 49

# State 45
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 - - x o o o o o 3
# 4 - x x o x x x o 4
# 5 - x o x x o x o 5
# 6 - x - - x x - o 6
# 7 o x - o x o o o 7
# 8 - - - - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 - - x o o o o o 3\n4 - x x o x x x o 4\n5 - x o x x o x o 5\n6 - x - - x x - o 6\n7 o x - o x o o o 7\n8 - - - - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 - - o x x x x x 3\n4 - o o x o o o x 4\n5 - o x o o x o x 5\n6 - o - - o o - x 6\n7 x o - x o x x x 7\n8 - - - - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◉◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◉◉◯◉◉◉◯  ◯◯◯◉◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◯◉◯  ◯◯◉◯◯◉◯◉
◉◯◉◉◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◯◯◯◯◉
◯◯◉◯◯◯◯◯  ◯◉◯◯◉◯◯◯  ◉◯◯◉◯◉◉◉
◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◉◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◉  ◯◉◉◯◉◉◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◉◯◉  ◯◉◯◉◉◯◉◯
◉◯◉◉◯◯◉◯  ◯◯◯◯◯◯◯◉  ◯◉◯◯◉◉◯◯
◯◯◉◯◯◯◯◯  ◉◯◯◉◯◉◉◉  ◯◉◯◯◉◯◯◯
◉◉◉◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 16, 17, 24, 32, 40, 42, 43, 46, 50, 59]
StringLegalActions() = ["c1 (o)", "a3 (o)", "b3 (o)", "a4 (o)", "a5 (o)", "a6 (o)", "c6 (o)", "d6 (o)", "g6 (o)", "c7 (o)", "d8 (o)"]

# Apply action "d6 (o)"
action: 43

# State 46
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 - - x o o o o o 3
# 4 - x x o x o x o 4
# 5 - x o o o o x o 5
# 6 - x - o x x - o 6
# 7 o x - o x o o o 7
# 8 - - - - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 - - x o o o o o 3\n4 - x x o x o x o 4\n5 - x o o o o x o 5\n6 - x - o x x - o 6\n7 o x - o x o o o 7\n8 - - - - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 - - o x x x x x 3\n4 - o o x o x o x 4\n5 - o x x x x o x 5\n6 - o - x o o - x 6\n7 x o - x o x x x 7\n8 - - - - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◉◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◉◉◯◉◯◉◯  ◯◯◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◯◯◯◉◯  ◯◯◉◉◉◉◯◉
◉◯◉◯◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◯◯◉◯◯◯◯◯  ◯◉◯◯◉◯◯◯  ◉◯◯◉◯◉◉◉
◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◉◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◉◯◉◯◉  ◯◉◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◉  ◯◉◯◯◯◯◉◯
◉◯◉◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◉◯◯◉◉◯◯
◯◯◉◯◯◯◯◯  ◉◯◯◉◯◉◉◉  ◯◉◯◯◉◯◯◯
◉◉◉◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 16, 17, 42, 46, 50, 58, 59, 61]
StringLegalActions() = ["c1 (x)", "a3 (x)", "b3 (x)", "c6 (x)", "g6 (x)", "c7 (x)", "c8 (x)", "d8 (x)", "f8 (x)"]

# Apply action "c8 (x)"
action: 58

# State 47
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 - - x o o o o o 3
# 4 - x x o x o x o 4
# 5 - x o o o o x o 5
# 6 - x - o x x - o 6
# 7 o x - x x o o o 7
# 8 - - x - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 - - x o o o o o 3\n4 - x x o x o x o 4\n5 - x o o o o x o 5\n6 - x - o x x - o 6\n7 o x - x x o o o 7\n8 - - x - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 - - o x x x x x 3\n4 - o o x o x o x 4\n5 - o x x x x o x 5\n6 - o - x o o - x 6\n7 x o - o o x x x 7\n8 - - o - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◉◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◉◉◯◉◯◉◯  ◯◯◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◯◯◯◉◯  ◯◯◉◉◉◉◯◉
◉◯◉◯◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◯◯◉◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◯◯◯◉◉◉
◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◉◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◉◯◉◯◉  ◯◉◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◉  ◯◉◯◯◯◯◉◯
◉◯◉◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◉◯◯◉◉◯◯
◯◯◉◯◯◯◯◯  ◉◯◯◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◉◉◯◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 16, 17, 24, 32, 40, 46, 50, 59, 61]
StringLegalActions() = ["c1 (o)", "a3 (o)", "b3 (o)", "a4 (o)", "a5 (o)", "a6 (o)", "g6 (o)", "c7 (o)", "d8 (o)", "f8 (o)"]

# Apply action "a3 (o)"
action: 16

# State 48
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 o - x o o o o o 3
# 4 - o x o x o x o 4
# 5 - x o o o o x o 5
# 6 - x - o x x - o 6
# 7 o x - x x o o o 7
# 8 - - x - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 o - x o o o o o 3\n4 - o x o x o x o 4\n5 - x o o o o x o 5\n6 - x - o x x - o 6\n7 o x - x x o o o 7\n8 - - x - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 x - o x x x x x 3\n4 - x o x o x o x 4\n5 - o x x x x o x 5\n6 - o - x o o - x 6\n7 x o - o o x x x 7\n8 - - o - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◯◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◯◯◯◉◯  ◯◯◉◉◉◉◯◉
◉◯◉◯◯◯◉◯  ◯◉◯◯◉◉◯◯  ◯◯◯◉◯◯◯◉
◯◯◉◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◯◯◯◉◉◉
◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◯◉◯◯◯◯◯◯  ◉◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◯◯◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◉◉◉◯◉  ◯◉◯◯◯◯◉◯
◉◯◉◯◯◯◉◯  ◯◯◯◉◯◯◯◉  ◯◉◯◯◉◉◯◯
◯◯◉◯◯◯◯◯  ◉◯◯◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◉◉◯◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 17, 24, 32, 42, 46, 61]
StringLegalActions() = ["c1 (x)", "b3 (x)", "a4 (x)", "a5 (x)", "c6 (x)", "g6 (x)", "f8 (x)"]

# Apply action "g6 (x)"
action: 46

# State 49
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 o - x o o o o o 3
# 4 - o x o x o x o 4
# 5 - x o o o x x o 5
# 6 - x - o x x x o 6
# 7 o x - x x x o o 7
# 8 - - x - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 o - x o o o o o 3\n4 - o x o x o x o 4\n5 - x o o o x x o 5\n6 - x - o x x x o 6\n7 o x - x x x o o 7\n8 - - x - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 x - o x x x x x 3\n4 - x o x o x o x 4\n5 - o x x x o o x 5\n6 - o - x o o o x 6\n7 x o - o o o x x 7\n8 - - o - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◯◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◉◯  ◯◯◉◉◉◯◯◉
◉◯◉◯◯◯◯◯  ◯◉◯◯◉◉◉◯  ◯◯◯◉◯◯◯◉
◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◯◯  ◉◯◯◯◯◯◉◉
◉◉◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◯◉◯◯◯◯◯◯  ◉◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◯◯◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◉  ◯◉◯◯◯◉◉◯
◉◯◉◯◯◯◯◯  ◯◯◯◉◯◯◯◉  ◯◉◯◯◉◉◉◯
◯◯◉◯◯◯◯◯  ◉◯◯◯◯◯◉◉  ◯◉◯◉◉◉◯◯
◉◉◯◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 17, 32, 40, 50, 57, 59, 61]
StringLegalActions() = ["c1 (o)", "b3 (o)", "a5 (o)", "a6 (o)", "c7 (o)", "b8 (o)", "d8 (o)", "f8 (o)"]

# Apply action "b8 (o)"
action: 57

# State 50
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 o - x o o o o o 3
# 4 - o x o x o x o 4
# 5 - o o o o x x o 5
# 6 - o - o x x x o 6
# 7 o o - x x x o o 7
# 8 - o x - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 o - x o o o o o 3\n4 - o x o x o x o 4\n5 - o o o o x x o 5\n6 - o - o x x x o 6\n7 o o - x x x o o 7\n8 - o x - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 x - o x x x x x 3\n4 - x o x o x o x 4\n5 - x x x x o o x 5\n6 - x - x o o o x 6\n7 x x - o o o x x 7\n8 - x o - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◯◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◉
◉◯◉◯◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◉◯◉◯◯◯◉
◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◯◯  ◉◉◯◯◯◯◉◉
◉◯◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯  ◯◉◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◯◉◯◯◯◯◯◯  ◉◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◯◯◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◉  ◯◯◯◯◉◉◉◯
◯◯◉◯◯◯◯◯  ◉◉◯◯◯◯◉◉  ◯◯◯◉◉◉◯◯
◉◯◯◉◯◉◯◯  ◯◉◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 17, 24, 32, 40, 42, 56]
StringLegalActions() = ["c1 (x)", "b3 (x)", "a4 (x)", "a5 (x)", "a6 (x)", "c6 (x)", "a8 (x)"]

# Apply action "a8 (x)"
action: 56

# State 51
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 o - x o o o o o 3
# 4 - o x o x o x o 4
# 5 - o o o o x x o 5
# 6 - o - o x x x o 6
# 7 o o - x x x o o 7
# 8 x x x - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 o - x o o o o o 3\n4 - o x o x o x o 4\n5 - o o o o x x o 5\n6 - o - o x x x o 6\n7 o o - x x x o o 7\n8 x x x - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 x - o x x x x x 3\n4 - x o x o x o x 4\n5 - x x x x o o x 5\n6 - x - x o o o x 6\n7 x x - o o o x x 7\n8 o o o - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◯◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◉
◉◯◉◯◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◉◯◉◯◯◯◉
◯◯◉◯◯◯◯◯  ◯◯◯◉◉◉◯◯  ◉◉◯◯◯◯◉◉
◯◯◯◉◯◉◯◯  ◉◉◉◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◯◉◯◯◯◯◯◯  ◉◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◯◯◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◉  ◯◯◯◯◉◉◉◯
◯◯◉◯◯◯◯◯  ◉◉◯◯◯◯◉◉  ◯◯◯◉◉◉◯◯
◯◯◯◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 17, 50, 59, 61]
StringLegalActions() = ["c1 (o)", "b3 (o)", "c7 (o)", "d8 (o)", "f8 (o)"]

# Apply action "c7 (o)"
action: 50

# State 52
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 o x o x x o o o 2
# 3 o - x o o o o o 3
# 4 - o x o x o x o 4
# 5 - o o o o x x o 5
# 6 - o - o x x x o 6
# 7 o o o o o o o o 7
# 8 x x x - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 o x o x x o o o 2\n3 o - x o o o o o 3\n4 - o x o x o x o 4\n5 - o o o o x x o 5\n6 - o - o x x x o 6\n7 o o o o o o o o 7\n8 x x x - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 x o x o o x x x 2\n3 x - o x x x x x 3\n4 - x o x o x o x 4\n5 - x x x x o o x 5\n6 - x - x o o o x 6\n7 x x x x x x x x 7\n8 o o o - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◉◉◯◯◯  ◉◯◉◯◯◉◉◉
◯◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◯  ◯◯◉◯◉◯◉◯  ◯◉◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◉
◉◯◉◯◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◉◯◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◉◯◉◯◯  ◉◉◉◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◯◯◉◉◉  ◯◉◯◉◉◯◯◯
◯◉◯◯◯◯◯◯  ◉◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◯◉◯◉◯◉  ◯◯◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◉  ◯◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 17, 24, 32, 40, 42, 59, 61]
StringLegalActions() = ["c1 (x)", "b3 (x)", "a4 (x)", "a5 (x)", "a6 (x)", "c6 (x)", "d8 (x)", "f8 (x)"]

# Apply action "a4 (x)"
action: 24

# State 53
#   a b c d e f g h
# 1 x x - x x x x x 1
# 2 x x o x x o o o 2
# 3 x - x o o o o o 3
# 4 x x x o x o x o 4
# 5 - o o o o x x o 5
# 6 - o - o x x x o 6
# 7 o o o o o o o o 7
# 8 x x x - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50, 24]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24"
ObservationString(0) = "  a b c d e f g h  \n1 x x - x x x x x 1\n2 x x o x x o o o 2\n3 x - x o o o o o 3\n4 x x x o x o x o 4\n5 - o o o o x x o 5\n6 - o - o x x x o 6\n7 o o o o o o o o 7\n8 x x x - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o - o o o o o 1\n2 o o x o o x x x 2\n3 o - o x x x x x 3\n4 o o o x o x o x 4\n5 - x x x x o o x 5\n6 - x - x o o o x 6\n7 x x x x x x x x 7\n8 o o o - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◉◉◯◉◯◉◯  ◯◯◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◉
◉◯◉◯◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◉◯◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◉◯◉◯◯  ◉◉◉◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◉◯◉◯◉  ◉◉◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◉  ◯◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 17]
StringLegalActions() = ["c1 (o)", "b3 (o)"]

# Apply action "c1 (o)"
action: 2

# State 54
#   a b c d e f g h
# 1 x x o x x x x x 1
# 2 x x o o x o o o 2
# 3 x - x o o o o o 3
# 4 x x x o x o x o 4
# 5 - o o o o x x o 5
# 6 - o - o x x x o 6
# 7 o o o o o o o o 7
# 8 x x x - x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50, 24, 2]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2"
ObservationString(0) = "  a b c d e f g h  \n1 x x o x x x x x 1\n2 x x o o x o o o 2\n3 x - x o o o o o 3\n4 x x x o x o x o 4\n5 - o o o o x x o 5\n6 - o - o x x x o 6\n7 o o o o o o o o 7\n8 x x x - x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o x o o o o o 1\n2 o o x x o x x x 2\n3 o - o x x x x x 3\n4 o o o x o x o x 4\n5 - x x x x o o x 5\n6 - x - x o o o x 6\n7 x x x x x x x x 7\n8 o o o - o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◯◉◯◯◯  ◯◯◉◉◯◉◉◉
◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◉◉◯◉◯◉◯  ◯◯◯◉◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◉
◉◯◉◯◯◯◯◯  ◯◯◯◯◉◉◉◯  ◯◉◯◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◉◯◉◯◯  ◉◉◉◯◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◉◯◉◉◉  ◉◉◯◯◉◯◯◯
◯◉◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◉◯◉◯◉  ◉◉◉◯◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◉  ◯◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◉◯◉◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◯◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [17, 32, 40, 42, 59, 61]
StringLegalActions() = ["b3 (x)", "a5 (x)", "a6 (x)", "c6 (x)", "d8 (x)", "f8 (x)"]

# Apply action "d8 (x)"
action: 59

# State 55
#   a b c d e f g h
# 1 x x o x x x x x 1
# 2 x x o x x o o o 2
# 3 x - x x o o o o 3
# 4 x x x x x o x o 4
# 5 - o o x o x x o 5
# 6 - o - x x x x o 6
# 7 o o o x x o o o 7
# 8 x x x x x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50, 24, 2, 59]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59"
ObservationString(0) = "  a b c d e f g h  \n1 x x o x x x x x 1\n2 x x o x x o o o 2\n3 x - x x o o o o 3\n4 x x x x x o x o 4\n5 - o o x o x x o 5\n6 - o - x x x x o 6\n7 o o o x x o o o 7\n8 x x x x x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o x o o o o o 1\n2 o o x o o x x x 2\n3 o - o o x x x x 3\n4 o o o o o x o x 4\n5 - x x o x o o x 5\n6 - x - o o o o x 6\n7 x x x o o x x x 7\n8 o o o o o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◉◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯  ◯◯◯◯◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◯◯◉◯◉◉◯  ◯◉◉◯◉◯◯◉
◉◯◉◯◯◯◯◯  ◯◯◯◉◉◉◉◯  ◯◉◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◉◉◉
◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◉◯◯◯◯◯◯  ◯◯◯◯◉◉◉◉  ◉◯◉◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◉  ◉◉◉◉◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◉◉◯◉◯◯◉  ◯◯◯◉◯◉◉◯
◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◉  ◯◯◯◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [17, 42, 61]
StringLegalActions() = ["b3 (o)", "c6 (o)", "f8 (o)"]

# Apply action "b3 (o)"
action: 17

# State 56
#   a b c d e f g h
# 1 x x o x x x x x 1
# 2 x x o x x o o o 2
# 3 x o o o o o o o 3
# 4 x o o x x o x o 4
# 5 - o o o o x x o 5
# 6 - o - x o x x o 6
# 7 o o o x x o o o 7
# 8 x x x x x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50, 24, 2, 59, 17]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17"
ObservationString(0) = "  a b c d e f g h  \n1 x x o x x x x x 1\n2 x x o x x o o o 2\n3 x o o o o o o o 3\n4 x o o x x o x o 4\n5 - o o o o x x o 5\n6 - o - x o x x o 6\n7 o o o x x o o o 7\n8 x x x x x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o x o o o o o 1\n2 o o x o o x x x 2\n3 o x x x x x x x 3\n4 o x x o o x o x 4\n5 - x x x x o o x 5\n6 - x - o x o o x 6\n7 x x x o o x x x 7\n8 o o o o o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◯◉◉◯◉◯  ◯◉◉◯◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◉
◉◯◉◯◯◯◯◯  ◯◯◯◉◯◉◉◯  ◯◉◯◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◉◉◉
◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◯◯◉◯◉  ◉◯◯◉◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◉◯◉◯◯◯◯◯  ◯◉◯◯◉◯◯◉  ◯◯◯◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [32, 40, 42, 61]
StringLegalActions() = ["a5 (x)", "a6 (x)", "c6 (x)", "f8 (x)"]

# Apply action "a6 (x)"
action: 40

# State 57
#   a b c d e f g h
# 1 x x o x x x x x 1
# 2 x x o x x o o o 2
# 3 x o o x o o o o 3
# 4 x o x x x o x o 4
# 5 - x o o o x x o 5
# 6 x o - x o x x o 6
# 7 x x o x x o o o 7
# 8 x x x x x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50, 24, 2, 59, 17, 40]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40"
ObservationString(0) = "  a b c d e f g h  \n1 x x o x x x x x 1\n2 x x o x x o o o 2\n3 x o o x o o o o 3\n4 x o x x x o x o 4\n5 - x o o o x x o 5\n6 x o - x o x x o 6\n7 x x o x x o o o 7\n8 x x x x x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o x o o o o o 1\n2 o o x o o x x x 2\n3 o x x o x x x x 3\n4 o x o o o x o x 4\n5 - o x x x o o x 5\n6 o x - o x o o x 6\n7 o o x o o x x x 7\n8 o o o o o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◯◉◯◯◯◯  ◯◉◉◯◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◉◯  ◯◉◯◯◯◉◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◯◯◉◉◯  ◯◯◉◉◉◯◯◉
◯◯◉◯◯◯◯◯  ◉◯◯◉◯◉◉◯  ◯◉◯◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◯◉◉◉◉  ◉◯◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◉  ◉◯◉◉◉◯◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◉  ◯◉◯◯◯◉◉◯
◯◯◉◯◯◯◯◯  ◯◉◯◯◉◯◯◉  ◉◯◯◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [32, 42, 61]
StringLegalActions() = ["a5 (o)", "c6 (o)", "f8 (o)"]

# Apply action "a5 (o)"
action: 32

# State 58
#   a b c d e f g h
# 1 x x o x x x x x 1
# 2 x x o x x o o o 2
# 3 x o o x o o o o 3
# 4 x o x x x o x o 4
# 5 o o o o o x x o 5
# 6 x o - x o x x o 6
# 7 x x o x x o o o 7
# 8 x x x x x - o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50, 24, 2, 59, 17, 40, 32]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32"
ObservationString(0) = "  a b c d e f g h  \n1 x x o x x x x x 1\n2 x x o x x o o o 2\n3 x o o x o o o o 3\n4 x o x x x o x o 4\n5 o o o o o x x o 5\n6 x o - x o x x o 6\n7 x x o x x o o o 7\n8 x x x x x - o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o x o o o o o 1\n2 o o x o o x x x 2\n3 o x x o x x x x 3\n4 o x o o o x o x 4\n5 x x x x x o o x 5\n6 o x - o x o o x 6\n7 o o x o o x x x 7\n8 o o o o o - x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◯◉◯◯◯◯  ◯◉◉◯◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◉◯  ◯◉◯◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◉
◯◯◉◯◯◯◯◯  ◉◯◯◉◯◉◉◯  ◯◉◯◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◯◉◉◉◉  ◉◯◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◉  ◉◯◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◯◯◉◯◯◯◯◯  ◯◉◯◯◉◯◯◉  ◉◯◯◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [42, 61]
StringLegalActions() = ["c6 (x)", "f8 (x)"]

# Apply action "f8 (x)"
action: 61

# State 59
#   a b c d e f g h
# 1 x x o x x x x x 1
# 2 x x o x x o o o 2
# 3 x o o x o o o o 3
# 4 x o x x x o x o 4
# 5 o o o o o x x o 5
# 6 x o - x o x x o 6
# 7 x x o x x x o o 7
# 8 x x x x x x o o 8
#   a b c d e f g h
IsTerminal() = False
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50, 24, 2, 59, 17, 40, 32, 61]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32 61"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32 61"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32 61"
ObservationString(0) = "  a b c d e f g h  \n1 x x o x x x x x 1\n2 x x o x x o o o 2\n3 x o o x o o o o 3\n4 x o x x x o x o 4\n5 o o o o o x x o 5\n6 x o - x o x x o 6\n7 x x o x x x o o 7\n8 x x x x x x o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o x o o o o o 1\n2 o o x o o x x x 2\n3 o x x o x x x x 3\n4 o x o o o x o x 4\n5 x x x x x o o x 5\n6 o x - o x o o x 6\n7 o o x o o o x x 7\n8 o o o o o o x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◯◉◯◯◯◯  ◯◉◉◯◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◉◯  ◯◉◯◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◉
◯◯◉◯◯◯◯◯  ◉◯◯◉◯◉◉◯  ◯◉◯◯◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◯◯  ◯◯◉◯◯◯◉◉
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◯◉◉◉◉  ◉◯◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◉  ◉◯◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◯◯◉◯◯◯◯◯  ◯◉◯◯◉◯◯◉  ◉◯◯◉◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◉◉  ◉◉◯◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◉◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [42]
StringLegalActions() = ["c6 (o)"]

# Apply action "c6 (o)"
action: 42

# State 60
#   a b c d e f g h
# 1 x x o x x x x x 1
# 2 x x o x x o o o 2
# 3 x o o x o o o o 3
# 4 x o x x x o x o 4
# 5 o o o o o x x o 5
# 6 x o o o o x x o 6
# 7 x x o x x x o o 7
# 8 x x x x x x o o 8
#   a b c d e f g h
IsTerminal() = True
History() = [37, 45, 53, 20, 19, 38, 29, 18, 47, 30, 9, 26, 21, 13, 25, 44, 31, 10, 12, 14, 6, 54, 55, 5, 1, 11, 3, 23, 39, 62, 52, 33, 7, 63, 41, 8, 0, 51, 4, 22, 60, 15, 34, 48, 49, 43, 58, 16, 46, 57, 56, 50, 24, 2, 59, 17, 40, 32, 61, 42]
HistoryString() = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32 61 42"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32 61 42"
InformationStateString(1) = "37 45 53 20 19 38 29 18 47 30 9 26 21 13 25 44 31 10 12 14 6 54 55 5 1 11 3 23 39 62 52 33 7 63 41 8 0 51 4 22 60 15 34 48 49 43 58 16 46 57 56 50 24 2 59 17 40 32 61 42"
ObservationString(0) = "  a b c d e f g h  \n1 x x o x x x x x 1\n2 x x o x x o o o 2\n3 x o o x o o o o 3\n4 x o x x x o x o 4\n5 o o o o o x x o 5\n6 x o o o o x x o 6\n7 x x o x x x o o 7\n8 x x x x x x o o 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o x o o o o o 1\n2 o o x o o x x x 2\n3 o x x o x x x x 3\n4 o x o o o x o x 4\n5 x x x x x o o x 5\n6 o x x x x o o x 6\n7 o o x o o o x x 7\n8 o o o o o o x x 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◯◉◯◯◯◯  ◯◉◉◯◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◯◉◉◉◯◉◯  ◯◉◯◯◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◉◉◯◯  ◯◯◉◯◯◯◉◉
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◉◉◉  ◉◉◯◉◉◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◉◯◉◉◉◉  ◉◯◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◉◯◯◯◉◯◉  ◉◯◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◉  ◉◯◯◯◯◉◉◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◉◉  ◉◉◯◉◉◉◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◉  ◉◉◉◉◉◉◯◯
Rewards() = [1.0, -1.0]
Returns() = [1.0, -1.0]
