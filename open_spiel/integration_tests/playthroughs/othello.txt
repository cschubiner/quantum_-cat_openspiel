game: othello

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Othello"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = []
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "othello"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 65
PolicyTensorShape() = [65]
MaxChanceOutcomes() = 0
GetParameters() = {}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [3, 8, 8]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 192
MaxGameLength() = 64
ToString() = "othello()"

# State 0
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - - - - - - 3
# 4 - - - o x - - - 4
# 5 - - - x o - - - 5
# 6 - - - - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - o x - - - 4\n5 - - - x o - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - - - - - - 3\n4 - - - x o - - - 4\n5 - - - o x - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [19, 26, 37, 44]
StringLegalActions() = ["d3", "c4", "f5", "e6"]

# Apply action "d3"
action: 19

# State 1
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 - - - x o - - - 5
# 6 - - - - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19]
HistoryString() = "19"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19"
InformationStateString(1) = "19"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 - - - x o - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 - - - o x - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 20, 34]
StringLegalActions() = ["c3", "e3", "c5"]

# Apply action "c5"
action: 34

# State 2
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 - - o o o - - - 5
# 6 - - - - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34]
HistoryString() = "19 34"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34"
InformationStateString(1) = "19 34"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 - - o o o - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 - - x x x - - - 5\n6 - - - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [41, 42, 43, 44, 45]
StringLegalActions() = ["b6", "c6", "d6", "e6", "f6"]

# Apply action "b6"
action: 41

# State 3
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 - - x o o - - - 5
# 6 - x - - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41]
HistoryString() = "19 34 41"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41"
InformationStateString(1) = "19 34 41"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 - - x o o - - - 5\n6 - x - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 - - o x x - - - 5\n6 - o - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [11, 18, 20, 21, 33]
StringLegalActions() = ["d2", "c3", "e3", "f3", "b5"]

# Apply action "b5"
action: 33

# State 4
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 - o o o o - - - 5
# 6 - x - - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33]
HistoryString() = "19 34 41 33"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33"
InformationStateString(1) = "19 34 41 33"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 - o o o o - - - 5\n6 - x - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 - x x x x - - - 5\n6 - o - - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [25, 42, 43, 44, 45]
StringLegalActions() = ["b4", "c6", "d6", "e6", "f6"]

# Apply action "c6"
action: 42

# State 5
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 - o o x o - - - 5
# 6 - x x - - - - - 6
# 7 - - - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42]
HistoryString() = "19 34 41 33 42"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42"
InformationStateString(1) = "19 34 41 33 42"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 - o o x o - - - 5\n6 - x x - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 - x x o x - - - 5\n6 - o o - - - - - 6\n7 - - - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◯◯◯
◉◯◯◉◉◉◉◉  ◯◉◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◯◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 20, 48, 49, 50, 51]
StringLegalActions() = ["c3", "e3", "a7", "b7", "c7", "d7"]

# Apply action "b7"
action: 49

# State 6
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 - o o x o - - - 5
# 6 - o x - - - - - 6
# 7 - o - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49]
HistoryString() = "19 34 41 33 42 49"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49"
InformationStateString(1) = "19 34 41 33 42 49"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 - o o x o - - - 5\n6 - o x - - - - - 6\n7 - o - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 - x x o x - - - 5\n6 - x o - - - - - 6\n7 - x - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◯◯◯
◉◯◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [24, 26, 32, 37, 40, 44, 45, 48, 56]
StringLegalActions() = ["a4", "c4", "a5", "f5", "a6", "e6", "f6", "a7", "a8"]

# Apply action "a6"
action: 40

# State 7
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 - o o x o - - - 5
# 6 x x x - - - - - 6
# 7 - o - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40]
HistoryString() = "19 34 41 33 42 49 40"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40"
InformationStateString(1) = "19 34 41 33 42 49 40"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 - o o x o - - - 5\n6 x x x - - - - - 6\n7 - o - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 - x x o x - - - 5\n6 o o o - - - - - 6\n7 - x - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◯◯◯
◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 20, 21, 48, 50, 51]
StringLegalActions() = ["c3", "e3", "f3", "a7", "c7", "d7"]

# Apply action "a7"
action: 48

# State 8
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 - o o x o - - - 5
# 6 x o x - - - - - 6
# 7 o o - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48]
HistoryString() = "19 34 41 33 42 49 40 48"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48"
InformationStateString(1) = "19 34 41 33 42 49 40 48"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 - o o x o - - - 5\n6 x o x - - - - - 6\n7 o o - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 - x x o x - - - 5\n6 o x o - - - - - 6\n7 x x - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◉◉◯◉◯◯◯
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◉◉◉  ◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [24, 26, 32, 37, 44, 45, 56, 58]
StringLegalActions() = ["a4", "c4", "a5", "f5", "e6", "f6", "a8", "c8"]

# Apply action "a5"
action: 32

# State 9
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 x x x x o - - - 5
# 6 x o x - - - - - 6
# 7 o o - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32]
HistoryString() = "19 34 41 33 42 49 40 48 32"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 x x x x o - - - 5\n6 x o x - - - - - 6\n7 o o - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 o o o o x - - - 5\n6 o x o - - - - - 6\n7 x x - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◉◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◉◉◉◉◉◉  ◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 20, 21, 24, 25, 43]
StringLegalActions() = ["c3", "e3", "f3", "a4", "b4", "d6"]

# Apply action "d6"
action: 43

# State 10
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 x x x x o - - - 5
# 6 x o o o - - - - 6
# 7 o o - - - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43]
HistoryString() = "19 34 41 33 42 49 40 48 32 43"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 x x x x o - - - 5\n6 x o o o - - - - 6\n7 o o - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 o o o o x - - - 5\n6 o x x x - - - - 6\n7 x x - - - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◉◉◉◉◉◉  ◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [37, 44, 45, 50, 51, 52, 56, 57, 58]
StringLegalActions() = ["f5", "e6", "f6", "c7", "d7", "e7", "a8", "b8", "c8"]

# Apply action "d7"
action: 51

# State 11
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 x x x x o - - - 5
# 6 x o x x - - - - 6
# 7 o o - x - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 x x x x o - - - 5\n6 x o x x - - - - 6\n7 o o - x - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 o o o o x - - - 5\n6 o x o o - - - - 6\n7 x x - o - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◉◉◯◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯
◯◯◉◯◉◉◉◉  ◉◉◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 20, 21, 24, 25, 44, 50]
StringLegalActions() = ["c3", "e3", "f3", "a4", "b4", "e6", "c7"]

# Apply action "c7"
action: 50

# State 12
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 x x x x o - - - 5
# 6 x o x o - - - - 6
# 7 o o o x - - - - 7
# 8 - - - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 x x x x o - - - 5\n6 x o x o - - - - 6\n7 o o o x - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 o o o o x - - - 5\n6 o x o x - - - - 6\n7 x x x o - - - - 7\n8 - - - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [37, 44, 45, 52, 56, 57, 58, 59]
StringLegalActions() = ["f5", "e6", "f6", "e7", "a8", "b8", "c8", "d8"]

# Apply action "b8"
action: 57

# State 13
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x - - - - 3
# 4 - - - x x - - - 4
# 5 x x x x o - - - 5
# 6 x x x o - - - - 6
# 7 o x o x - - - - 7
# 8 - x - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x - - - - 3\n4 - - - x x - - - 4\n5 x x x x o - - - 5\n6 x x x o - - - - 6\n7 o x o x - - - - 7\n8 - x - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o - - - - 3\n4 - - - o o - - - 4\n5 o o o o x - - - 5\n6 o o o x - - - - 6\n7 x o x o - - - - 7\n8 - o - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [11, 18, 20, 24, 25, 26, 52, 59]
StringLegalActions() = ["d2", "c3", "e3", "a4", "b4", "c4", "e7", "d8"]

# Apply action "e3"
action: 20

# State 14
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x o - - - 3
# 4 - - - o o - - - 4
# 5 x x o x o - - - 5
# 6 x o x o - - - - 6
# 7 o x o x - - - - 7
# 8 - x - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x o - - - 3\n4 - - - o o - - - 4\n5 x x o x o - - - 5\n6 x o x o - - - - 6\n7 o x o x - - - - 7\n8 - x - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o x - - - 3\n4 - - - x x - - - 4\n5 o o x o x - - - 5\n6 o x o x - - - - 6\n7 x o x o - - - - 7\n8 - o - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [21, 26, 29, 37, 44, 56, 58, 59]
StringLegalActions() = ["f3", "c4", "f4", "f5", "e6", "a8", "c8", "d8"]

# Apply action "e6"
action: 44

# State 15
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - - - - - - 2
# 3 - - - x o - - - 3
# 4 - - - o o - - - 4
# 5 x x o x o - - - 5
# 6 x o x x x - - - 6
# 7 o x o x - - - - 7
# 8 - x - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - x o - - - 3\n4 - - - o o - - - 4\n5 x x o x o - - - 5\n6 x o x x x - - - 6\n7 o x o x - - - - 7\n8 - x - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - - - - - - 2\n3 - - - o x - - - 3\n4 - - - x x - - - 4\n5 o o x o x - - - 5\n6 o x o o o - - - 6\n7 x o x o - - - - 7\n8 - o - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◉◉◉◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [10, 11, 18, 24, 25, 45, 52, 56, 59]
StringLegalActions() = ["c2", "d2", "c3", "a4", "b4", "f6", "e7", "a8", "d8"]

# Apply action "d2"
action: 11

# State 16
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - o - - - - 2
# 3 - - - o o - - - 3
# 4 - - - o o - - - 4
# 5 x x o x o - - - 5
# 6 x o x x x - - - 6
# 7 o x o x - - - - 7
# 8 - x - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - o - - - - 2\n3 - - - o o - - - 3\n4 - - - o o - - - 4\n5 x x o x o - - - 5\n6 x o x x x - - - 6\n7 o x o x - - - - 7\n8 - x - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - x - - - - 2\n3 - - - x x - - - 3\n4 - - - x x - - - 4\n5 o o x o x - - - 5\n6 o x o o o - - - 6\n7 x o x o - - - - 7\n8 - o - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◉◉◉◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 12, 21, 25, 26, 29, 37, 56, 58, 59]
StringLegalActions() = ["d1", "e2", "f3", "b4", "c4", "f4", "f5", "a8", "c8", "d8"]

# Apply action "c4"
action: 26

# State 17
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - o - - - - 2
# 3 - - - o o - - - 3
# 4 - - x o o - - - 4
# 5 x x x x o - - - 5
# 6 x o x x x - - - 6
# 7 o x o x - - - - 7
# 8 - x - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - o - - - - 2\n3 - - - o o - - - 3\n4 - - x o o - - - 4\n5 x x x x o - - - 5\n6 x o x x x - - - 6\n7 o x o x - - - - 7\n8 - x - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - x - - - - 2\n3 - - - x x - - - 3\n4 - - o x x - - - 4\n5 o o o o x - - - 5\n6 o x o o o - - - 6\n7 x o x o - - - - 7\n8 - o - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◉◉◉◯◯◯  ◯◉◯◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◉◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◯◉◯◯◯◯◯  ◯◉◯◉◯◯◯◯
◉◯◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [18, 24, 25, 45, 52, 56, 59]
StringLegalActions() = ["c3", "a4", "b4", "f6", "e7", "a8", "d8"]

# Apply action "a8"
action: 56

# State 18
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - o - - - - 2
# 3 - - - o o - - - 3
# 4 - - x o o - - - 4
# 5 x x x o o - - - 5
# 6 x o o x x - - - 6
# 7 o o o x - - - - 7
# 8 o x - - - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - o - - - - 2\n3 - - - o o - - - 3\n4 - - x o o - - - 4\n5 x x x o o - - - 5\n6 x o o x x - - - 6\n7 o o o x - - - - 7\n8 o x - - - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - x - - - - 2\n3 - - - x x - - - 3\n4 - - o x x - - - 4\n5 o o o x x - - - 5\n6 o x x o o - - - 6\n7 x x x o - - - - 7\n8 x o - - - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◯◉◉◯◯◯  ◯◉◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◉◉◉◉◉◉  ◯◉◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◉◉◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 12, 13, 29, 37, 58, 59]
StringLegalActions() = ["d1", "e2", "f2", "f4", "f5", "c8", "d8"]

# Apply action "d8"
action: 59

# State 19
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - o - - - - 2
# 3 - - - o o - - - 3
# 4 - - x o o - - - 4
# 5 x x x o o - - - 5
# 6 x x o x x - - - 6
# 7 o o x x - - - - 7
# 8 o x - x - - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - o - - - - 2\n3 - - - o o - - - 3\n4 - - x o o - - - 4\n5 x x x o o - - - 5\n6 x x o x x - - - 6\n7 o o x x - - - - 7\n8 o x - x - - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - x - - - - 2\n3 - - - x x - - - 3\n4 - - o x x - - - 4\n5 o o o x x - - - 5\n6 o o x o o - - - 6\n7 x x o o - - - - 7\n8 x o - o - - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◉◉◯◯◯◯  ◉◉◯◯◯◯◯◯
◯◯◉◯◉◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◯◯◯◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯
◯◯◉◯◉◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◯◉◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [17, 18, 24, 25, 45, 52, 53, 58, 60]
StringLegalActions() = ["b3", "c3", "a4", "b4", "f6", "e7", "f7", "c8", "e8"]

# Apply action "e8"
action: 60

# State 20
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - o - - - - 2
# 3 - - - o o - - - 3
# 4 - - x o o - - - 4
# 5 x x x o o - - - 5
# 6 x x o x x - - - 6
# 7 o o x o - - - - 7
# 8 o x - x o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - o - - - - 2\n3 - - - o o - - - 3\n4 - - x o o - - - 4\n5 x x x o o - - - 5\n6 x x o x x - - - 6\n7 o o x o - - - - 7\n8 o x - x o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - x - - - - 2\n3 - - - x x - - - 3\n4 - - o x x - - - 4\n5 o o o x x - - - 5\n6 o o x o o - - - 6\n7 x x o x - - - - 7\n8 x o - o x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◯◯◯◯
◯◯◉◯◯◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◯◯◉◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◉◯◯◉◉◉  ◉◯◯◯◉◯◯◯  ◯◉◯◉◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 12, 13, 29, 37, 52, 58, 61]
StringLegalActions() = ["d1", "e2", "f2", "f4", "f5", "e7", "c8", "f8"]

# Apply action "e2"
action: 12

# State 21
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - o x - - - 2
# 3 - - - x x - - - 3
# 4 - - x o x - - - 4
# 5 x x x o x - - - 5
# 6 x x o x x - - - 6
# 7 o o x o - - - - 7
# 8 o x - x o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - o x - - - 2\n3 - - - x x - - - 3\n4 - - x o x - - - 4\n5 x x x o x - - - 5\n6 x x o x x - - - 6\n7 o o x o - - - - 7\n8 o x - x o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - x o - - - 2\n3 - - - o o - - - 3\n4 - - o x o - - - 4\n5 o o o x o - - - 5\n6 o o x o o - - - 6\n7 x x o x - - - - 7\n8 x o - o x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◯◯◯◯
◯◯◉◯◯◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◯◯◉◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◉◯◯◉◉◉  ◉◯◯◯◉◯◯◯  ◯◉◯◉◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [13, 17, 18, 21, 24, 25, 29, 37, 45, 53, 58]
StringLegalActions() = ["f2", "b3", "c3", "f3", "a4", "b4", "f4", "f5", "f6", "f7", "c8"]

# Apply action "c8"
action: 58

# State 22
#   a b c d e f g h
# 1 - - - - - - - - 1
# 2 - - - o x - - - 2
# 3 - - - x x - - - 3
# 4 - - x o x - - - 4
# 5 x x x o x - - - 5
# 6 x x o x x - - - 6
# 7 o o o o - - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58"
ObservationString(0) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - o x - - - 2\n3 - - - x x - - - 3\n4 - - x o x - - - 4\n5 x x x o x - - - 5\n6 x x o x x - - - 6\n7 o o o o - - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - - - - - - - 1\n2 - - - x o - - - 2\n3 - - - o o - - - 3\n4 - - o x o - - - 4\n5 o o o x o - - - 5\n6 o o x o o - - - 6\n7 x x x x - - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 3, 10, 18]
StringLegalActions() = ["c1", "d1", "c2", "c3"]

# Apply action "c1"
action: 2

# State 23
#   a b c d e f g h
# 1 - - x - - - - - 1
# 2 - - - x x - - - 2
# 3 - - - x x - - - 3
# 4 - - x o x - - - 4
# 5 x x x o x - - - 5
# 6 x x o x x - - - 6
# 7 o o o o - - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2"
ObservationString(0) = "  a b c d e f g h  \n1 - - x - - - - - 1\n2 - - - x x - - - 2\n3 - - - x x - - - 3\n4 - - x o x - - - 4\n5 x x x o x - - - 5\n6 x x o x x - - - 6\n7 o o o o - - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o - - - - - 1\n2 - - - o o - - - 2\n3 - - - o o - - - 3\n4 - - o x o - - - 4\n5 o o o x o - - - 5\n6 o o x o o - - - 6\n7 x x x x - - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◉◉◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 13, 17, 18, 21, 24, 25, 29, 37, 45, 53]
StringLegalActions() = ["d1", "f2", "b3", "c3", "f3", "a4", "b4", "f4", "f5", "f6", "f7"]

# Apply action "d1"
action: 3

# State 24
#   a b c d e f g h
# 1 - - x o - - - - 1
# 2 - - - o x - - - 2
# 3 - - - o x - - - 3
# 4 - - x o x - - - 4
# 5 x x x o x - - - 5
# 6 x x o x x - - - 6
# 7 o o o o - - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3"
ObservationString(0) = "  a b c d e f g h  \n1 - - x o - - - - 1\n2 - - - o x - - - 2\n3 - - - o x - - - 3\n4 - - x o x - - - 4\n5 x x x o x - - - 5\n6 x x o x x - - - 6\n7 o o o o - - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o x - - - - 1\n2 - - - x o - - - 2\n3 - - - x o - - - 3\n4 - - o x o - - - 4\n5 o o o x o - - - 5\n6 o o x o o - - - 6\n7 x x x x - - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◉◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◉◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 10, 18]
StringLegalActions() = ["e1", "c2", "c3"]

# Apply action "e1"
action: 4

# State 25
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - - o x - - - 2
# 3 - - - o x - - - 3
# 4 - - x o x - - - 4
# 5 x x x o x - - - 5
# 6 x x o x x - - - 6
# 7 o o o o - - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - - o x - - - 2\n3 - - - o x - - - 3\n4 - - x o x - - - 4\n5 x x x o x - - - 5\n6 x x o x x - - - 6\n7 o o o o - - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - - x o - - - 2\n3 - - - x o - - - 3\n4 - - o x o - - - 4\n5 o o o x o - - - 5\n6 o o x o o - - - 6\n7 x x x x - - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◉◉◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 13, 17, 18, 21, 24, 25, 29, 37, 45, 53]
StringLegalActions() = ["f1", "f2", "b3", "c3", "f3", "a4", "b4", "f4", "f5", "f6", "f7"]

# Apply action "b4"
action: 25

# State 26
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - - o x - - - 2
# 3 - - - o x - - - 3
# 4 - o o o x - - - 4
# 5 x o x o x - - - 5
# 6 x o o x x - - - 6
# 7 o o o o - - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - - o x - - - 2\n3 - - - o x - - - 3\n4 - o o o x - - - 4\n5 x o x o x - - - 5\n6 x o o x x - - - 6\n7 o o o o - - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - - x o - - - 2\n3 - - - x o - - - 3\n4 - x x x o - - - 4\n5 o x o x o - - - 5\n6 o x x o o - - - 6\n7 x x x x - - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◉◯◉◯◯◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◯◉◉◯◯◯  ◯◉◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [10, 16, 17, 18, 24]
StringLegalActions() = ["c2", "a3", "b3", "c3", "a4"]

# Apply action "c2"
action: 10

# State 27
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - x x x - - - 2
# 3 - - - x x - - - 3
# 4 - o o o x - - - 4
# 5 x o x o x - - - 5
# 6 x o o x x - - - 6
# 7 o o o o - - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - x x x - - - 2\n3 - - - x x - - - 3\n4 - o o o x - - - 4\n5 x o x o x - - - 5\n6 x o o x x - - - 6\n7 o o o o - - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - o o o - - - 2\n3 - - - o o - - - 3\n4 - x x x o - - - 4\n5 o x o x o - - - 5\n6 o x x o o - - - 6\n7 x x x x - - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◉◯◉◯◯◯  ◯◉◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◯◉◉◯◯◯  ◯◉◉◯◯◯◯◯
◯◯◯◯◉◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◯◉◯◯◯◯  ◉◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◉◯◯◯◯◯  ◉◯◯◉◉◯◯◯
◯◯◯◯◉◉◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 13, 21, 24, 29, 37, 45, 52, 53]
StringLegalActions() = ["f1", "f2", "f3", "a4", "f4", "f5", "f6", "e7", "f7"]

# Apply action "e7"
action: 52

# State 28
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - x x x - - - 2
# 3 - - - x x - - - 3
# 4 - o o o x - - - 4
# 5 x o o o x - - - 5
# 6 x o o o x - - - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - x x x - - - 2\n3 - - - x x - - - 3\n4 - o o o x - - - 4\n5 x o o o x - - - 5\n6 x o o o x - - - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - o o o - - - 2\n3 - - - o o - - - 3\n4 - x x x o - - - 4\n5 o x x x o - - - 5\n6 o x x x o - - - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◉◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [17, 18, 24]
StringLegalActions() = ["b3", "c3", "a4"]

# Apply action "c3"
action: 18

# State 29
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - x x x - - - 2
# 3 - - x x x - - - 3
# 4 - x o x x - - - 4
# 5 x o o o x - - - 5
# 6 x o o o x - - - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - x x x - - - 2\n3 - - x x x - - - 3\n4 - x o x x - - - 4\n5 x o o o x - - - 5\n6 x o o o x - - - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - o o o - - - 2\n3 - - o o o - - - 3\n4 - o x o o - - - 4\n5 o x x x o - - - 5\n6 o x x x o - - - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◯◯◯◉◯◯◯  ◯◉◉◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◉◉◯◯◯◯  ◉◯◯◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 13, 16, 17, 21, 24, 29, 37, 45, 53]
StringLegalActions() = ["f1", "f2", "a3", "b3", "f3", "a4", "f4", "f5", "f6", "f7"]

# Apply action "f5"
action: 37

# State 30
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - x x x - - - 2
# 3 - - x x x - - - 3
# 4 - x o x x - - - 4
# 5 x o o o o o - - 5
# 6 x o o o o - - - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - x x x - - - 2\n3 - - x x x - - - 3\n4 - x o x x - - - 4\n5 x o o o o o - - 5\n6 x o o o o - - - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - o o o - - - 2\n3 - - o o o - - - 3\n4 - o x o o - - - 4\n5 o x x x x x - - 5\n6 o x x x x - - - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◯◯◯◯◯◉◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◉◉◉◉◯◯◯  ◉◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [38, 45, 46, 61]
StringLegalActions() = ["g5", "f6", "g6", "f8"]

# Apply action "g6"
action: 46

# State 31
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - x x x - - - 2
# 3 - - x x x - - - 3
# 4 - x o x x - - - 4
# 5 x o o o o x - - 5
# 6 x o o o o - x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - x x x - - - 2\n3 - - x x x - - - 3\n4 - x o x x - - - 4\n5 x o o o o x - - 5\n6 x o o o o - x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - o o o - - - 2\n3 - - o o o - - - 3\n4 - o x o o - - - 4\n5 o x x x x o - - 5\n6 o x x x x - o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◉◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◯◯◯◯◉◯◯  ◯◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◉  ◉◯◯◯◯◯◉◯  ◯◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◉◉◉◉◯◯◯  ◉◯◯◯◯◉◯◯
◯◯◯◯◯◉◯◉  ◯◉◉◉◉◯◯◯  ◉◯◯◯◯◯◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 9, 13, 16, 17, 21, 24, 29, 30, 38]
StringLegalActions() = ["f1", "b2", "f2", "a3", "b3", "f3", "a4", "f4", "g4", "g5"]

# Apply action "a4"
action: 24

# State 32
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - x x x - - - 2
# 3 - - x x x - - - 3
# 4 o o o x x - - - 4
# 5 o o o o o x - - 5
# 6 o o o o o - x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - x x x - - - 2\n3 - - x x x - - - 3\n4 o o o x x - - - 4\n5 o o o o o x - - 5\n6 o o o o o - x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - o o o - - - 2\n3 - - o o o - - - 3\n4 x x x o o - - - 4\n5 x x x x x o - - 5\n6 x x x x x - o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◉  ◯◯◯◯◯◯◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◉◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [45]
StringLegalActions() = ["f6"]

# Apply action "f6"
action: 45

# State 33
#   a b c d e f g h
# 1 - - x x x - - - 1
# 2 - - x x x - - - 2
# 3 - - x x x - - - 3
# 4 o o o x x - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x - - - 1\n2 - - x x x - - - 2\n3 - - x x x - - - 3\n4 o o o x x - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o - - - 1\n2 - - o o o - - - 2\n3 - - o o o - - - 3\n4 x x x o o - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [5, 13, 21, 29, 30, 38, 47]
StringLegalActions() = ["f1", "f2", "f3", "f4", "g4", "g5", "h6"]

# Apply action "f1"
action: 5

# State 34
#   a b c d e f g h
# 1 - - x x x o - - 1
# 2 - - x x o - - - 2
# 3 - - x o x - - - 3
# 4 o o o x x - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x o - - 1\n2 - - x x o - - - 2\n3 - - x o x - - - 3\n4 o o o x x - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o x - - 1\n2 - - o o x - - - 2\n3 - - o x o - - - 3\n4 x x x o o - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◯◯◯◯  ◯◯◯◯◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◉◯◯◯  ◯◯◉◉◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [6, 13, 21]
StringLegalActions() = ["g1", "f2", "f3"]

# Apply action "f3"
action: 21

# State 35
#   a b c d e f g h
# 1 - - x x x o - - 1
# 2 - - x x x - - - 2
# 3 - - x o x x - - 3
# 4 o o o x x - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21"
ObservationString(0) = "  a b c d e f g h  \n1 - - x x x o - - 1\n2 - - x x x - - - 2\n3 - - x o x x - - 3\n4 o o o x x - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - - o o o x - - 1\n2 - - o o o - - - 2\n3 - - o x o o - - 3\n4 x x x o o - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◉◯◯◯◯◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◉◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◯◉◉◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◉◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 13, 14, 17, 22, 29, 30, 38, 47, 55]
StringLegalActions() = ["b1", "f2", "g2", "b3", "g3", "f4", "g4", "g5", "h6", "h7"]

# Apply action "b1"
action: 1

# State 36
#   a b c d e f g h
# 1 - o o o o o - - 1
# 2 - - o x x - - - 2
# 3 - - x o x x - - 3
# 4 o o o x x - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1"
ObservationString(0) = "  a b c d e f g h  \n1 - o o o o o - - 1\n2 - - o x x - - - 2\n3 - - x o x x - - 3\n4 o o o x x - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - x x x x x - - 1\n2 - - x o o - - - 2\n3 - - o x o o - - 3\n4 x x x o o - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◉◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◉◉◉  ◯◯◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◉◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [9]
StringLegalActions() = ["b2"]

# Apply action "b2"
action: 9

# State 37
#   a b c d e f g h
# 1 - o o o o o - - 1
# 2 - x x x x - - - 2
# 3 - - x o x x - - 3
# 4 o o o x x - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9"
ObservationString(0) = "  a b c d e f g h  \n1 - o o o o o - - 1\n2 - x x x x - - - 2\n3 - - x o x x - - 3\n4 o o o x x - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - x x x x x - - 1\n2 - o o o o - - - 2\n3 - - o x o o - - 3\n4 x x x o o - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◉◉◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◉◉◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◉◯◯◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◉◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [13, 14, 16, 17, 22, 29, 30, 38, 47, 55]
StringLegalActions() = ["f2", "g2", "a3", "b3", "g3", "f4", "g4", "g5", "h6", "h7"]

# Apply action "g2"
action: 14

# State 38
#   a b c d e f g h
# 1 - o o o o o - - 1
# 2 - x x x x - o - 2
# 3 - - x o x o - - 3
# 4 o o o x o - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14"
ObservationString(0) = "  a b c d e f g h  \n1 - o o o o o - - 1\n2 - x x x x - o - 2\n3 - - x o x o - - 3\n4 o o o x o - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - x x x x x - - 1\n2 - o o o o - x - 2\n3 - - o x o x - - 3\n4 x x x o x - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◉◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◯◉◯
◉◉◯◯◯◯◉◉  ◯◯◉◯◉◯◯◯  ◯◯◯◉◯◉◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◯◉  ◯◯◯◯◯◯◉◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◉◉  ◯◯◯◉◯◉◯◯  ◯◯◉◯◉◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [22, 29, 30]
StringLegalActions() = ["g3", "f4", "g4"]

# Apply action "g3"
action: 22

# State 39
#   a b c d e f g h
# 1 - o o o o o - - 1
# 2 - x x x x - o - 2
# 3 - - x o x x x - 3
# 4 o o o x o - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22"
ObservationString(0) = "  a b c d e f g h  \n1 - o o o o o - - 1\n2 - x x x x - o - 2\n3 - - x o x x x - 3\n4 o o o x o - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - x x x x x - - 1\n2 - o o o o - x - 2\n3 - - o x o o o - 3\n4 x x x o x - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◉◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◯◉◯
◉◉◯◯◯◯◯◉  ◯◯◉◯◉◉◉◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◉◯◉  ◯◯◯◯◯◯◉◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◉◯◯◯◯  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [13, 16, 17, 23, 29, 30, 38, 47, 55]
StringLegalActions() = ["f2", "a3", "b3", "h3", "f4", "g4", "g5", "h6", "h7"]

# Apply action "f2"
action: 13

# State 40
#   a b c d e f g h
# 1 - o o o o o - - 1
# 2 - x x x x o o - 2
# 3 - - x o o x x - 3
# 4 o o o o o - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13"
ObservationString(0) = "  a b c d e f g h  \n1 - o o o o o - - 1\n2 - x x x x o o - 2\n3 - - x o o x x - 3\n4 o o o o o - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - x x x x x - - 1\n2 - o o o o x x - 2\n3 - - o x x o o - 3\n4 x x x x x - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◉◉◯◯◯◯◯◉  ◯◯◉◯◯◉◉◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [6, 7, 15, 29]
StringLegalActions() = ["g1", "h1", "h2", "f4"]

# Apply action "h2"
action: 15

# State 41
#   a b c d e f g h
# 1 - o o o o o - - 1
# 2 - x x x x x x x 2
# 3 - - x o o x x - 3
# 4 o o o o o - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15"
ObservationString(0) = "  a b c d e f g h  \n1 - o o o o o - - 1\n2 - x x x x x x x 2\n3 - - x o o x x - 3\n4 o o o o o - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - x x x x x - - 1\n2 - o o o o o o o 2\n3 - - o x x o o - 3\n4 x x x x x - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◉◉◯◯◯◯◯◉  ◯◯◉◯◯◉◉◯  ◯◯◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◉◉
◉◉◯◯◯◯◯◉  ◯◯◯◉◉◯◯◯  ◯◯◉◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 6, 7, 16, 17, 23, 29, 30, 31, 38, 47, 54, 55]
StringLegalActions() = ["a1", "g1", "h1", "a3", "b3", "h3", "f4", "g4", "h4", "g5", "h6", "g7", "h7"]

# Apply action "b3"
action: 17

# State 42
#   a b c d e f g h
# 1 - o o o o o - - 1
# 2 - o o x x x x x 2
# 3 - o o o o x x - 3
# 4 o o o o o - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17"
ObservationString(0) = "  a b c d e f g h  \n1 - o o o o o - - 1\n2 - o o x x x x x 2\n3 - o o o o x x - 3\n4 o o o o o - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 - x x x x x - - 1\n2 - x x o o o o o 2\n3 - x x x x o o - 3\n4 x x x x x - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◉◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◯◉◉◯◯◯◯◯
◉◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◯◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◉◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◉◯◯◯◯◯◯◉  ◯◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 8, 16, 29]
StringLegalActions() = ["a1", "a2", "a3", "f4"]

# Apply action "a1"
action: 0

# State 43
#   a b c d e f g h
# 1 x o o o o o - - 1
# 2 - x o x x x x x 2
# 3 - o x o o x x - 3
# 4 o o o x o - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0"
ObservationString(0) = "  a b c d e f g h  \n1 x o o o o o - - 1\n2 - x o x x x x x 2\n3 - o x o o x x - 3\n4 o o o x o - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o x x x x x - - 1\n2 - o x o o o o o 2\n3 - x o x x o o - 3\n4 x x x o x - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◉◉  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◉  ◯◯◉◯◯◉◉◯  ◯◉◯◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◉◉  ◯◉◉◉◉◉◯◯  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◉
◉◯◯◯◯◯◯◉  ◯◉◯◉◉◯◯◯  ◯◯◉◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [6, 7, 8, 16, 23, 29, 30, 31, 38, 47, 55]
StringLegalActions() = ["g1", "h1", "a2", "a3", "h3", "f4", "g4", "h4", "g5", "h6", "h7"]

# Apply action "h1"
action: 7

# State 44
#   a b c d e f g h
# 1 x o o o o o - o 1
# 2 - x o x x x o x 2
# 3 - o x o o o x - 3
# 4 o o o x o - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7"
ObservationString(0) = "  a b c d e f g h  \n1 x o o o o o - o 1\n2 - x o x x x o x 2\n3 - o x o o o x - 3\n4 o o o x o - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o x x x x x - x 1\n2 - o x o o o x o 2\n3 - x o x x x o - 3\n4 x x x o x - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◉◯  ◉◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◯◉  ◯◯◉◯◯◯◉◯
◉◯◯◯◯◯◯◉  ◯◯◉◯◯◯◉◯  ◯◉◯◉◉◉◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◉◯  ◯◉◉◉◉◉◯◉  ◉◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◉◯  ◯◉◯◉◉◉◯◉
◉◯◯◯◯◯◯◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [6, 16, 29, 30]
StringLegalActions() = ["g1", "a3", "f4", "g4"]

# Apply action "g1"
action: 6

# State 45
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 - x o x x x x x 2
# 3 - o x o o o x - 3
# 4 o o o x o - - - 4
# 5 o o o o x x - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 - x o x x x x x 2\n3 - o x o o o x - 3\n4 o o o x o - - - 4\n5 o o o o x x - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 - o x o o o o o 2\n3 - x o x x x o - 3\n4 x x x o x - - - 4\n5 x x x x o o - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◉  ◯◯◉◯◯◯◉◯  ◯◉◯◉◉◉◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◉◯◯  ◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◉
◉◯◯◯◯◯◯◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◯◉◯◯◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◯◯◯  ◯◯◯◯◉◉◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [8, 23, 29, 30, 38, 47, 55]
StringLegalActions() = ["a2", "h3", "f4", "g4", "g5", "h6", "h7"]

# Apply action "g4"
action: 30

# State 46
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 - x o x x x x x 2
# 3 - o x o o o x - 3
# 4 o o o x o - o - 4
# 5 o o o o x o - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 - x o x x x x x 2\n3 - o x o o o x - 3\n4 o o o x o - o - 4\n5 o o o o x o - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 - o x o o o o o 2\n3 - x o x x x o - 3\n4 x x x o x - x - 4\n5 x x x x o x - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◉◯◯◯◯◯◯◉  ◯◯◉◯◯◯◉◯  ◯◉◯◉◉◉◯◯
◯◯◯◯◯◉◯◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◉
◉◯◯◯◯◯◯◉  ◯◉◯◉◉◉◯◯  ◯◯◉◯◯◯◉◯
◯◯◯◯◯◉◯◉  ◉◉◉◯◉◯◉◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [16, 29, 38, 39]
StringLegalActions() = ["a3", "f4", "g5", "h5"]

# Apply action "a3"
action: 16

# State 47
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 - x o x x x x x 2
# 3 x x x o o o x - 3
# 4 o o o x o - o - 4
# 5 o o o o x o - - 5
# 6 o o o o o x x - 6
# 7 o o o o o - - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 - x o x x x x x 2\n3 x x x o o o x - 3\n4 o o o x o - o - 4\n5 o o o o x o - - 5\n6 o o o o o x x - 6\n7 o o o o o - - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 - o x o o o o o 2\n3 o o o x x x o - 3\n4 x x x o x - x - 4\n5 x x x x o x - - 5\n6 x x x x x o o - 6\n7 x x x x x - - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◉◯◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◉◯◉  ◉◉◉◯◉◯◉◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [8, 23, 29, 38, 47, 53, 55]
StringLegalActions() = ["a2", "h3", "f4", "g5", "h6", "f7", "h7"]

# Apply action "f7"
action: 53

# State 48
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 - x o x x x x x 2
# 3 x x x o o o x - 3
# 4 o o o x o - o - 4
# 5 o o o o x o - - 5
# 6 o o o o o o x - 6
# 7 o o o o o o - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 - x o x x x x x 2\n3 x x x o o o x - 3\n4 o o o x o - o - 4\n5 o o o o x o - - 5\n6 o o o o o o x - 6\n7 o o o o o o - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 - o x o o o o o 2\n3 o o o x x x o - 3\n4 x x x o x - x - 4\n5 x x x x o x - - 5\n6 x x x x x x o - 6\n7 x x x x x x - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◉◯◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◉◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◉◯◉  ◉◉◉◯◉◯◉◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [29, 38, 39, 54, 61, 62]
StringLegalActions() = ["f4", "g5", "h5", "g7", "f8", "g8"]

# Apply action "f4"
action: 29

# State 49
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 - x o x x x x x 2
# 3 x x x o x x x - 3
# 4 o o o x x x o - 4
# 5 o o o o x o - - 5
# 6 o o o o o o x - 6
# 7 o o o o o o - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 - x o x x x x x 2\n3 x x x o x x x - 3\n4 o o o x x x o - 4\n5 o o o o x o - - 5\n6 o o o o o o x - 6\n7 o o o o o o - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 - o x o o o o o 2\n3 o o o x o o o - 3\n4 x x x o o o x - 4\n5 x x x x o x - - 5\n6 x x x x x x o - 6\n7 x x x x x x - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◉◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◉  ◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◉◉◉◯  ◯◯◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◉◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯  ◯◉◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◉◯◯◯◯  ◉◉◉◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [8, 23, 39, 47, 55]
StringLegalActions() = ["a2", "h3", "h5", "h6", "h7"]

# Apply action "a2"
action: 8

# State 50
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x x 2
# 3 o o x o x x x - 3
# 4 o o o x x x o - 4
# 5 o o o o x o - - 5
# 6 o o o o o o x - 6
# 7 o o o o o o - - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x x 2\n3 o o x o x x x - 3\n4 o o o x x x o - 4\n5 o o o o x o - - 5\n6 o o o o o o x - 6\n7 o o o o o o - - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o o 2\n3 x x o x o o o - 3\n4 x x x o o o x - 4\n5 x x x x o x - - 5\n6 x x x x x x o - 6\n7 x x x x x x - - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◉◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [31, 38, 39, 54, 61]
StringLegalActions() = ["h4", "g5", "h5", "g7", "f8"]

# Apply action "g7"
action: 54

# State 51
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x x 2
# 3 o o x o x x x - 3
# 4 o o o x x x o - 4
# 5 o o o o x o - - 5
# 6 o o o o o x x - 6
# 7 o o o o o o x - 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x x 2\n3 o o x o x x x - 3\n4 o o o x x x o - 4\n5 o o o o x o - - 5\n6 o o o o o x x - 6\n7 o o o o o o x - 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o o 2\n3 x x o x o o o - 3\n4 x x x o o o x - 4\n5 x x x x o x - - 5\n6 x x x x x o o - 6\n7 x x x x x x o - 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◉◯  ◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯◯  ◯◯◯◯◯◯◉◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [23, 38, 39, 47, 55, 63]
StringLegalActions() = ["h3", "g5", "h5", "h6", "h7", "h8"]

# Apply action "h7"
action: 55

# State 52
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x x 2
# 3 o o x o x x x - 3
# 4 o o o x x x o - 4
# 5 o o o o x o - - 5
# 6 o o o o o x o - 6
# 7 o o o o o o o o 7
# 8 o o o o o - - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x x 2\n3 o o x o x x x - 3\n4 o o o x x x o - 4\n5 o o o o x o - - 5\n6 o o o o o x o - 6\n7 o o o o o o o o 7\n8 o o o o o - - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o o 2\n3 x x o x o o o - 3\n4 x x x o o o x - 4\n5 x x x x o x - - 5\n6 x x x x x o x - 6\n7 x x x x x x x x 7\n8 x x x x x - - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◉◉◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◉◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [31, 38, 39, 47, 61, 63]
StringLegalActions() = ["h4", "g5", "h5", "h6", "f8", "h8"]

# Apply action "f8"
action: 61

# State 53
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x x 2
# 3 o o x o x x x - 3
# 4 o o o x x x o - 4
# 5 o o o o x o - - 5
# 6 o o o o o x o - 6
# 7 o o o o o x o o 7
# 8 o o o o o x - - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x x 2\n3 o o x o x x x - 3\n4 o o o x x x o - 4\n5 o o o o x o - - 5\n6 o o o o o x o - 6\n7 o o o o o x o o 7\n8 o o o o o x - - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o o 2\n3 x x o x o o o - 3\n4 x x x o o o x - 4\n5 x x x x o x - - 5\n6 x x x x x o x - 6\n7 x x x x x o x x 7\n8 x x x x x o - - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◉◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◉◯◯◯  ◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [23, 38, 62]
StringLegalActions() = ["h3", "g5", "g8"]

# Apply action "g8"
action: 62

# State 54
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x x 2
# 3 o o x o x x x - 3
# 4 o o o x x x o - 4
# 5 o o o o x o - - 5
# 6 o o o o o x o - 6
# 7 o o o o o o o o 7
# 8 o o o o o o o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61, 62]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x x 2\n3 o o x o x x x - 3\n4 o o o x x x o - 4\n5 o o o o x o - - 5\n6 o o o o o x o - 6\n7 o o o o o o o o 7\n8 o o o o o o o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o o 2\n3 x x o x o o o - 3\n4 x x x o o o x - 4\n5 x x x x o x - - 5\n6 x x x x x o x - 6\n7 x x x x x x x x 7\n8 x x x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◯◯  ◉◉◉◯◯◯◉◯
◯◯◯◯◯◯◉◉  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◉◯  ◯◯◯◉◉◉◯◯
◯◯◯◯◯◯◉◉  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [31, 38, 39, 47, 63]
StringLegalActions() = ["h4", "g5", "h5", "h6", "h8"]

# Apply action "h5"
action: 39

# State 55
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x x 2
# 3 o o x o x x x - 3
# 4 o o o x x x x - 4
# 5 o o o o x o - x 5
# 6 o o o o o x o - 6
# 7 o o o o o o o o 7
# 8 o o o o o o o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61, 62, 39]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x x 2\n3 o o x o x x x - 3\n4 o o o x x x x - 4\n5 o o o o x o - x 5\n6 o o o o o x o - 6\n7 o o o o o o o o 7\n8 o o o o o o o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o o 2\n3 x x o x o o o - 3\n4 x x x o o o o - 4\n5 x x x x o x - o 5\n6 x x x x x o x - 6\n7 x x x x x x x x 7\n8 x x x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◉◉◉◉◯  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◉◯  ◯◯◯◯◉◯◯◉  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◉  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◯
◯◯◯◯◯◯◉◯  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◉
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [23, 31, 38]
StringLegalActions() = ["h3", "h4", "g5"]

# Apply action "h4"
action: 31

# State 56
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x x 2
# 3 o o x o x x x - 3
# 4 o o o o o o o o 4
# 5 o o o o x o - x 5
# 6 o o o o o x o - 6
# 7 o o o o o o o o 7
# 8 o o o o o o o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61, 62, 39, 31]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x x 2\n3 o o x o x x x - 3\n4 o o o o o o o o 4\n5 o o o o x o - x 5\n6 o o o o o x o - 6\n7 o o o o o o o o 7\n8 o o o o o o o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o o 2\n3 x x o x o o o - 3\n4 x x x x x x x x 4\n5 x x x x o x - o 5\n6 x x x x x o x - 6\n7 x x x x x x x x 7\n8 x x x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◉◯  ◯◯◯◯◉◯◯◉  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◯  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◉
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [23, 38, 47, 63]
StringLegalActions() = ["h3", "g5", "h6", "h8"]

# Apply action "h3"
action: 23

# State 57
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x x 2
# 3 o o x o x x x x 3
# 4 o o o o o o o x 4
# 5 o o o o x o - x 5
# 6 o o o o o x o - 6
# 7 o o o o o o o o 7
# 8 o o o o o o o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61, 62, 39, 31, 23]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x x 2\n3 o o x o x x x x 3\n4 o o o o o o o x 4\n5 o o o o x o - x 5\n6 o o o o o x o - 6\n7 o o o o o o o o 7\n8 o o o o o o o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o o 2\n3 x x o x o o o o 3\n4 x x x x x x x o 4\n5 x x x x o x - o 5\n6 x x x x x o x - 6\n7 x x x x x x x x 7\n8 x x x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◉  ◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◉◉  ◉◉◯◉◯◯◯◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◉◯  ◯◯◯◯◉◯◯◉  ◉◉◉◉◯◉◯◯
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◯
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯  ◯◯◯◉◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◯◯◯  ◯◯◉◯◉◉◉◉
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◉◯  ◉◉◉◉◯◉◯◯  ◯◯◯◯◉◯◯◉
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◯◉◯  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [38, 47]
StringLegalActions() = ["g5", "h6"]

# Apply action "h6"
action: 47

# State 58
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x o 2
# 3 o o x o x x x o 3
# 4 o o o o o o o o 4
# 5 o o o o x o - o 5
# 6 o o o o o x o o 6
# 7 o o o o o o o o 7
# 8 o o o o o o o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61, 62, 39, 31, 23, 47]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x o 2\n3 o o x o x x x o 3\n4 o o o o o o o o 4\n5 o o o o x o - o 5\n6 o o o o o x o o 6\n7 o o o o o o o o 7\n8 o o o o o o o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o x 2\n3 x x o x o o o x 3\n4 x x x x x x x x 4\n5 x x x x o x - x 5\n6 x x x x x o x x 6\n7 x x x x x x x x 7\n8 x x x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯  ◉◉◉◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◉◯  ◯◯◯◯◉◯◯◯  ◉◉◉◉◯◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◯◯◉  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◉◯  ◉◉◉◉◯◉◯◉  ◯◯◯◯◉◯◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [38, 63]
StringLegalActions() = ["g5", "h8"]

# Apply action "g5"
action: 38

# State 59
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x o 2
# 3 o o x o x x x o 3
# 4 o o o o o x x o 4
# 5 o o o o x x x o 5
# 6 o o o o o x o o 6
# 7 o o o o o o o o 7
# 8 o o o o o o o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61, 62, 39, 31, 23, 47, 38]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x o 2\n3 o o x o x x x o 3\n4 o o o o o x x o 4\n5 o o o o x x x o 5\n6 o o o o o x o o 6\n7 o o o o o o o o 7\n8 o o o o o o o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o x 2\n3 x x o x o o o x 3\n4 x x x x x o o x 4\n5 x x x x o o o x 5\n6 x x x x x o x x 6\n7 x x x x x x x x 7\n8 x x x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯  ◉◉◉◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◉◯  ◉◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◯◯◉  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◉  ◯◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [64]
StringLegalActions() = ["pass"]

# Apply action "pass"
action: 64

# State 60
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x o 2
# 3 o o x o x x x o 3
# 4 o o o o o x x o 4
# 5 o o o o x x x o 5
# 6 o o o o o x o o 6
# 7 o o o o o o o o 7
# 8 o o o o o o o - 8
#   a b c d e f g h
IsTerminal() = False
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61, 62, 39, 31, 23, 47, 38, 64]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38 64"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38 64"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38 64"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x o 2\n3 o o x o x x x o 3\n4 o o o o o x x o 4\n5 o o o o x x x o 5\n6 o o o o o x o o 6\n7 o o o o o o o o 7\n8 o o o o o o o - 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o x 2\n3 x x o x o o o x 3\n4 x x x x x o o x 4\n5 x x x x o o o x 5\n6 x x x x x o x x 6\n7 x x x x x x x x 7\n8 x x x x x x x - 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯  ◉◉◉◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◉◯  ◉◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◯◯◉  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◉  ◯◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [63]
StringLegalActions() = ["h8"]

# Apply action "h8"
action: 63

# State 61
#   a b c d e f g h
# 1 x x x x x x x o 1
# 2 o o o x x x x o 2
# 3 o o x o x x x o 3
# 4 o o o o o x x o 4
# 5 o o o o x x x o 5
# 6 o o o o o x o o 6
# 7 o o o o o o x o 7
# 8 o o o o o o o x 8
#   a b c d e f g h
IsTerminal() = True
History() = [19, 34, 41, 33, 42, 49, 40, 48, 32, 43, 51, 50, 57, 20, 44, 11, 26, 56, 59, 60, 12, 58, 2, 3, 4, 25, 10, 52, 18, 37, 46, 24, 45, 5, 21, 1, 9, 14, 22, 13, 15, 17, 0, 7, 6, 30, 16, 53, 29, 8, 54, 55, 61, 62, 39, 31, 23, 47, 38, 64, 63]
HistoryString() = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38 64 63"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38 64 63"
InformationStateString(1) = "19 34 41 33 42 49 40 48 32 43 51 50 57 20 44 11 26 56 59 60 12 58 2 3 4 25 10 52 18 37 46 24 45 5 21 1 9 14 22 13 15 17 0 7 6 30 16 53 29 8 54 55 61 62 39 31 23 47 38 64 63"
ObservationString(0) = "  a b c d e f g h  \n1 x x x x x x x o 1\n2 o o o x x x x o 2\n3 o o x o x x x o 3\n4 o o o o o x x o 4\n5 o o o o x x x o 5\n6 o o o o o x o o 6\n7 o o o o o o x o 7\n8 o o o o o o o x 8\n  a b c d e f g h  "
ObservationString(1) = "  a b c d e f g h  \n1 o o o o o o o x 1\n2 x x x o o o o x 2\n3 x x o x o o o x 3\n4 x x x x x o o x 4\n5 x x x x o o o x 5\n6 x x x x x o x x 6\n7 x x x x x x o x 7\n8 x x x x x x x o 8\n  a b c d e f g h  "
ObservationTensor(0):
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◉◉◉◉◯  ◉◉◉◯◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◉◯◉◉◉◯  ◉◉◯◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◉◯  ◉◉◉◉◉◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◉◉◉◯  ◉◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯  ◉◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯  ◉◉◉◉◉◉◯◉
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◉  ◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◉  ◯◯◯◉◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◯◉◯◯◯◉  ◯◯◉◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◉  ◯◯◯◯◯◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◉  ◯◯◯◯◉◉◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◉◉  ◯◯◯◯◯◉◯◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◉  ◯◯◯◯◯◯◉◯
◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯◉
Rewards() = [-1.0, 1.0]
Returns() = [-1.0, 1.0]
