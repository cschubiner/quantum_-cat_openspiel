game: python_dominoes

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "Python Dominoes (4 players)"
GameType.max_num_players = 4
GameType.min_num_players = 4
GameType.parameter_specification = []
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = True
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "python_dominoes"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 308
PolicyTensorShape() = [308]
MaxChanceOutcomes() = 28
GetParameters() = {}
NumPlayers() = 4
MinUtility() = -100.0
MaxUtility() = 100.0
UtilitySum() = 0.0
InformationStateTensorShape() = player: [4], hand: [7, 3], actions_history: [25, 5]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 150
ObservationTensorShape() = player: [4], hand: [7, 3], last_action: [4], hand_sizes: [4]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 33
MaxGameLength() = 28
ToString() = "python_dominoes()"

# State 0
# hand0:[]
# hand1:[]
# hand2:[]
# hand3:[]
#
# board: []
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = PlayerId.CHANCE
InformationStateString(0) = "p0 hand:[] history:[]"
InformationStateString(1) = "p1 hand:[] history:[]"
InformationStateString(2) = "p2 hand:[] history:[]"
InformationStateString(3) = "p3 hand:[] history:[]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand: ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
InformationStateTensor(0).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand: ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
InformationStateTensor(1).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand: ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
InformationStateTensor(2).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand: ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
InformationStateTensor(3).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
ObservationString(0) = "p0 hand:[]"
ObservationString(1) = "p1 hand:[]"
ObservationString(2) = "p2 hand:[]"
ObservationString(3) = "p3 hand:[]"
PublicObservationString() = "p0"
PrivateObservationString(0) = "p0 hand:[]"
PrivateObservationString(1) = "p1 hand:[]"
PrivateObservationString(2) = "p2 hand:[]"
PrivateObservationString(3) = "p3 hand:[]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand: ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
ObservationTensor(0).last_action: ◯◯◯◯
ObservationTensor(0).hand_sizes: ◯◯◯◯
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand: ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
ObservationTensor(1).last_action: ◯◯◯◯
ObservationTensor(1).hand_sizes: ◯◯◯◯
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand: ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
ObservationTensor(2).last_action: ◯◯◯◯
ObservationTensor(2).hand_sizes: ◯◯◯◯
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand: ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
ObservationTensor(3).last_action: ◯◯◯◯
ObservationTensor(3).hand_sizes: ◯◯◯◯
ChanceOutcomes() = [(0,0.0357143), (1,0.0357143), (2,0.0357143), (3,0.0357143), (4,0.0357143), (5,0.0357143), (6,0.0357143), (7,0.0357143), (8,0.0357143), (9,0.0357143), (10,0.0357143), (11,0.0357143), (12,0.0357143), (13,0.0357143), (14,0.0357143), (15,0.0357143), (16,0.0357143), (17,0.0357143), (18,0.0357143), (19,0.0357143), (20,0.0357143), (21,0.0357143), (22,0.0357143), (23,0.0357143), (24,0.0357143), (25,0.0357143), (26,0.0357143), (27,0.0357143)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]
StringLegalActions() = ["Deal (0.0, 0.0)", "Deal (0.0, 1.0)", "Deal (0.0, 2.0)", "Deal (0.0, 3.0)", "Deal (0.0, 4.0)", "Deal (0.0, 5.0)", "Deal (0.0, 6.0)", "Deal (1.0, 1.0)", "Deal (1.0, 2.0)", "Deal (1.0, 3.0)", "Deal (1.0, 4.0)", "Deal (1.0, 5.0)", "Deal (1.0, 6.0)", "Deal (2.0, 2.0)", "Deal (2.0, 3.0)", "Deal (2.0, 4.0)", "Deal (2.0, 5.0)", "Deal (2.0, 6.0)", "Deal (3.0, 3.0)", "Deal (3.0, 4.0)", "Deal (3.0, 5.0)", "Deal (3.0, 6.0)", "Deal (4.0, 4.0)", "Deal (4.0, 5.0)", "Deal (4.0, 6.0)", "Deal (5.0, 5.0)", "Deal (5.0, 6.0)", "Deal (6.0, 6.0)"]

# Apply action "Deal (1.0, 3.0)"
action: 9

# State 1
# hand0:['(1.0, 3.0)']
# hand1:[]
# hand2:[]
# hand3:[]
#
# board: []
IsTerminal() = False
History() = [9]
HistoryString() = "9"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = PlayerId.CHANCE
InformationStateString(0) = "p0 hand:[(1.0, 3.0)] history:[]"
InformationStateString(1) = "p1 hand:[] history:[]"
InformationStateString(2) = "p2 hand:[] history:[]"
InformationStateString(3) = "p3 hand:[] history:[]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand: ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
InformationStateTensor(1).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand: ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
InformationStateTensor(2).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand: ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
                                ◯◯◯
InformationStateTensor(3).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
ObservationString(0) = "p0 hand:[(1.0, 3.0)]"
ObservationString(1) = "p1 hand:[]"
ObservationString(2) = "p2 hand:[]"
ObservationString(3) = "p3 hand:[]"
PublicObservationString() = "p0"
PrivateObservationString(0) = "p0 hand:[(1.0, 3.0)]"
PrivateObservationString(1) = "p1 hand:[]"
PrivateObservationString(2) = "p2 hand:[]"
PrivateObservationString(3) = "p3 hand:[]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action: ◯◯◯◯
ObservationTensor(0).hand_sizes: ◉◯◯◯
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand: ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
ObservationTensor(1).last_action: ◯◯◯◯
ObservationTensor(1).hand_sizes: ◯◉◯◯
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand: ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
ObservationTensor(2).last_action: ◯◯◯◯
ObservationTensor(2).hand_sizes: ◯◯◯◯
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand: ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
                           ◯◯◯
ObservationTensor(3).last_action: ◯◯◯◯
ObservationTensor(3).hand_sizes: ◯◯◯◯
ChanceOutcomes() = [(0,0.037037), (1,0.037037), (2,0.037037), (3,0.037037), (4,0.037037), (5,0.037037), (6,0.037037), (7,0.037037), (8,0.037037), (10,0.037037), (11,0.037037), (12,0.037037), (13,0.037037), (14,0.037037), (15,0.037037), (16,0.037037), (17,0.037037), (18,0.037037), (19,0.037037), (20,0.037037), (21,0.037037), (22,0.037037), (23,0.037037), (24,0.037037), (25,0.037037), (26,0.037037), (27,0.037037)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]
StringLegalActions() = ["Deal (0.0, 0.0)", "Deal (0.0, 1.0)", "Deal (0.0, 2.0)", "Deal (0.0, 3.0)", "Deal (0.0, 4.0)", "Deal (0.0, 5.0)", "Deal (0.0, 6.0)", "Deal (1.0, 1.0)", "Deal (1.0, 2.0)", "Deal (1.0, 4.0)", "Deal (1.0, 5.0)", "Deal (1.0, 6.0)", "Deal (2.0, 2.0)", "Deal (2.0, 3.0)", "Deal (2.0, 4.0)", "Deal (2.0, 5.0)", "Deal (2.0, 6.0)", "Deal (3.0, 3.0)", "Deal (3.0, 4.0)", "Deal (3.0, 5.0)", "Deal (3.0, 6.0)", "Deal (4.0, 4.0)", "Deal (4.0, 5.0)", "Deal (4.0, 6.0)", "Deal (5.0, 5.0)", "Deal (5.0, 6.0)", "Deal (6.0, 6.0)"]

# Apply action "Deal (3.0, 3.0)"
action: 18

# State 2
# Apply action "Deal (0.0, 5.0)"
action: 5

# State 3
# Apply action "Deal (1.0, 5.0)"
action: 11

# State 4
# Apply action "Deal (2.0, 3.0)"
action: 14

# State 5
# Apply action "Deal (2.0, 4.0)"
action: 15

# State 6
# Apply action "Deal (3.0, 4.0)"
action: 19

# State 7
# Apply action "Deal (1.0, 6.0)"
action: 12

# State 8
# Apply action "Deal (5.0, 6.0)"
action: 26

# State 9
# Apply action "Deal (3.0, 6.0)"
action: 21

# State 10
# Apply action "Deal (6.0, 6.0)"
action: 27

# State 11
# Apply action "Deal (3.0, 5.0)"
action: 20

# State 12
# Apply action "Deal (1.0, 1.0)"
action: 7

# State 13
# Apply action "Deal (0.0, 6.0)"
action: 6

# State 14
# Apply action "Deal (0.0, 4.0)"
action: 4

# State 15
# Apply action "Deal (0.0, 1.0)"
action: 1

# State 16
# Apply action "Deal (5.0, 5.0)"
action: 25

# State 17
# Apply action "Deal (4.0, 6.0)"
action: 24

# State 18
# Apply action "Deal (1.0, 2.0)"
action: 8

# State 19
# Apply action "Deal (4.0, 5.0)"
action: 23

# State 20
# Apply action "Deal (0.0, 3.0)"
action: 3

# State 21
# Apply action "Deal (1.0, 4.0)"
action: 10

# State 22
# Apply action "Deal (2.0, 6.0)"
action: 17

# State 23
# Apply action "Deal (0.0, 2.0)"
action: 2

# State 24
# Apply action "Deal (4.0, 4.0)"
action: 22

# State 25
# Apply action "Deal (2.0, 2.0)"
action: 13

# State 26
# Apply action "Deal (2.0, 5.0)"
action: 16

# State 27
# Apply action "Deal (0.0, 0.0)"
action: 0

# State 28
# hand0:['(0.0, 3.0)', '(1.0, 1.0)', '(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(0.0, 6.0)', '(1.0, 4.0)', '(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(0.0, 5.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(3.0, 4.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 1.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(1.0, 6.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: []
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "p0 hand:[(0.0, 3.0), (1.0, 1.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[]"
InformationStateString(1) = "p1 hand:[(0.0, 6.0), (1.0, 4.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)] history:[]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)] history:[]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0]
InformationStateTensor(0).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [0.0, 6.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0]
InformationStateTensor(1).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 1.0]
InformationStateTensor(2).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0]
InformationStateTensor(3).actions_history: ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
ObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 1.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
ObservationString(1) = "p1 hand:[(0.0, 6.0), (1.0, 4.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)]"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)]"
PublicObservationString() = "p0"
PrivateObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 1.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(0.0, 6.0), (1.0, 4.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0]
ObservationTensor(0).last_action: ◯◯◯◯
ObservationTensor(0).hand_sizes = [7.0, 7.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [0.0, 6.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0]
ObservationTensor(1).last_action: ◯◯◯◯
ObservationTensor(1).hand_sizes = [7.0, 7.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 1.0]
ObservationTensor(2).last_action: ◯◯◯◯
ObservationTensor(2).hand_sizes = [7.0, 7.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0]
ObservationTensor(3).last_action: ◯◯◯◯
ObservationTensor(3).hand_sizes = [7.0, 7.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [8, 20, 25, 39, 62, 70, 72]
StringLegalActions() = ["p0 tile:(0.0, 3.0) pip:None", "p0 tile:(1.0, 1.0) pip:None", "p0 tile:(1.0, 3.0) pip:None", "p0 tile:(2.0, 3.0) pip:None", "p0 tile:(4.0, 4.0) pip:None", "p0 tile:(5.0, 5.0) pip:None", "p0 tile:(5.0, 6.0) pip:None"]

# Apply action "p0 tile:(1.0, 1.0) pip:None"
action: 20

# State 29
# hand0:['(0.0, 3.0)', '(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(0.0, 6.0)', '(1.0, 4.0)', '(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(0.0, 5.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(3.0, 4.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 1.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(1.0, 6.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(1.0, 1.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None]"
InformationStateString(1) = "p1 hand:[(0.0, 6.0), (1.0, 4.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history: ◉◉◯◯◉
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [0.0, 6.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0]
InformationStateTensor(1).actions_history: ◉◉◯◯◉
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 1.0]
InformationStateTensor(2).actions_history: ◉◉◯◯◉
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0]
InformationStateTensor(3).actions_history: ◉◉◯◯◉
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
                                           ◯◯◯◯◯
ObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] last_action:p0 tile:(1.0, 1.0) pip:None"
ObservationString(1) = "p1 hand:[(0.0, 6.0), (1.0, 4.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p0 tile:(1.0, 1.0) pip:None"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)] last_action:p0 tile:(1.0, 1.0) pip:None"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)] last_action:p0 tile:(1.0, 1.0) pip:None"
PublicObservationString() = "p0 last_action:p0 tile:(1.0, 1.0) pip:None"
PrivateObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(0.0, 6.0), (1.0, 4.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action: ◉◉◯◯
ObservationTensor(0).hand_sizes = [6.0, 7.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [0.0, 6.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0]
ObservationTensor(1).last_action: ◉◉◯◯
ObservationTensor(1).hand_sizes = [7.0, 6.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 1.0]
ObservationTensor(2).last_action: ◉◉◯◯
ObservationTensor(2).hand_sizes = [7.0, 7.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0]
ObservationTensor(3).last_action: ◉◉◯◯
ObservationTensor(3).hand_sizes = [7.0, 7.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [106]
StringLegalActions() = ["p1 tile:(1.0, 4.0) pip:1.0"]

# Apply action "p1 tile:(1.0, 4.0) pip:1.0"
action: 106

# State 30
# hand0:['(0.0, 3.0)', '(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(0.0, 6.0)', '(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(0.0, 5.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(3.0, 4.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 1.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(1.0, 6.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(4.0, 1.0), (1.0, 1.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 2
InformationStateString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0]"
InformationStateString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [0.0, 6.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 1.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] last_action:p1 tile:(1.0, 4.0) pip:1.0"
ObservationString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p1 tile:(1.0, 4.0) pip:1.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)] last_action:p1 tile:(1.0, 4.0) pip:1.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)] last_action:p1 tile:(1.0, 4.0) pip:1.0"
PublicObservationString() = "p0 last_action:p1 tile:(1.0, 4.0) pip:1.0"
PrivateObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (3.0, 4.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [1.0, 4.0, 1.0, 1.0]
ObservationTensor(0).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [0.0, 6.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [1.0, 4.0, 1.0, 1.0]
ObservationTensor(1).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 1.0]
ObservationTensor(2).last_action = [1.0, 4.0, 1.0, 1.0]
ObservationTensor(2).hand_sizes = [7.0, 7.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0]
ObservationTensor(3).last_action = [1.0, 4.0, 1.0, 1.0]
ObservationTensor(3).hand_sizes = [7.0, 7.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [167, 177, 209]
StringLegalActions() = ["p2 tile:(0.0, 4.0) pip:4.0", "p2 tile:(1.0, 2.0) pip:1.0", "p2 tile:(3.0, 4.0) pip:4.0"]

# Apply action "p2 tile:(3.0, 4.0) pip:4.0"
action: 209

# State 31
# hand0:['(0.0, 3.0)', '(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(0.0, 6.0)', '(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(0.0, 5.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 1.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(1.0, 6.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(3.0, 4.0), (4.0, 1.0), (1.0, 1.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 3
InformationStateString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0]"
InformationStateString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [0.0, 6.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] last_action:p2 tile:(3.0, 4.0) pip:4.0"
ObservationString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p2 tile:(3.0, 4.0) pip:4.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] last_action:p2 tile:(3.0, 4.0) pip:4.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)] last_action:p2 tile:(3.0, 4.0) pip:4.0"
PublicObservationString() = "p0 last_action:p2 tile:(3.0, 4.0) pip:4.0"
PrivateObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (1.0, 6.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [3.0, 4.0, 4.0, 2.0]
ObservationTensor(0).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [0.0, 6.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [3.0, 4.0, 4.0, 2.0]
ObservationTensor(1).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [3.0, 4.0, 4.0, 2.0]
ObservationTensor(2).hand_sizes = [6.0, 7.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0]
ObservationTensor(3).last_action = [3.0, 4.0, 4.0, 2.0]
ObservationTensor(3).hand_sizes = [7.0, 6.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [235, 263, 266, 288]
StringLegalActions() = ["p3 tile:(0.0, 1.0) pip:1.0", "p3 tile:(1.0, 5.0) pip:1.0", "p3 tile:(1.0, 6.0) pip:1.0", "p3 tile:(3.0, 5.0) pip:3.0"]

# Apply action "p3 tile:(1.0, 6.0) pip:1.0"
action: 266

# State 32
# hand0:['(0.0, 3.0)', '(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(0.0, 6.0)', '(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(0.0, 5.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 1.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0]"
InformationStateString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [0.0, 6.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] last_action:p3 tile:(1.0, 6.0) pip:1.0"
ObservationString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p3 tile:(1.0, 6.0) pip:1.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] last_action:p3 tile:(1.0, 6.0) pip:1.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] last_action:p3 tile:(1.0, 6.0) pip:1.0"
PublicObservationString() = "p0 last_action:p3 tile:(1.0, 6.0) pip:1.0"
PrivateObservationString(0) = "p0 hand:[(0.0, 3.0), (1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [1.0, 6.0, 1.0, 3.0]
ObservationTensor(0).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [0.0, 6.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [1.0, 6.0, 1.0, 3.0]
ObservationTensor(1).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [1.0, 6.0, 1.0, 3.0]
ObservationTensor(2).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [1.0, 6.0, 1.0, 3.0]
ObservationTensor(3).hand_sizes = [6.0, 6.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [10, 27, 41, 74]
StringLegalActions() = ["p0 tile:(0.0, 3.0) pip:3.0", "p0 tile:(1.0, 3.0) pip:3.0", "p0 tile:(2.0, 3.0) pip:3.0", "p0 tile:(5.0, 6.0) pip:6.0"]

# Apply action "p0 tile:(0.0, 3.0) pip:3.0"
action: 10

# State 33
# hand0:['(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(0.0, 6.0)', '(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(0.0, 5.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 1.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(0.0, 3.0), (3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0]"
InformationStateString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [0.0, 6.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] last_action:p0 tile:(0.0, 3.0) pip:3.0"
ObservationString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p0 tile:(0.0, 3.0) pip:3.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] last_action:p0 tile:(0.0, 3.0) pip:3.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] last_action:p0 tile:(0.0, 3.0) pip:3.0"
PublicObservationString() = "p0 last_action:p0 tile:(0.0, 3.0) pip:3.0"
PrivateObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(0.0, 6.0), (2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [0.0, 3.0, 3.0, 0.0]
ObservationTensor(0).hand_sizes = [5.0, 6.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [0.0, 6.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [0.0, 3.0, 3.0, 0.0]
ObservationTensor(1).hand_sizes = [6.0, 5.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [0.0, 3.0, 3.0, 0.0]
ObservationTensor(2).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [0.0, 3.0, 3.0, 0.0]
ObservationTensor(3).hand_sizes = [6.0, 6.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [95, 96, 138, 146]
StringLegalActions() = ["p1 tile:(0.0, 6.0) pip:0.0", "p1 tile:(0.0, 6.0) pip:6.0", "p1 tile:(3.0, 6.0) pip:6.0", "p1 tile:(4.0, 6.0) pip:6.0"]

# Apply action "p1 tile:(0.0, 6.0) pip:6.0"
action: 96

# State 34
# hand0:['(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(0.0, 5.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 1.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(0.0, 3.0), (3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0), (6.0, 0.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 2
InformationStateString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0]"
InformationStateString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] last_action:p1 tile:(0.0, 6.0) pip:6.0"
ObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p1 tile:(0.0, 6.0) pip:6.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] last_action:p1 tile:(0.0, 6.0) pip:6.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] last_action:p1 tile:(0.0, 6.0) pip:6.0"
PublicObservationString() = "p0 last_action:p1 tile:(0.0, 6.0) pip:6.0"
PrivateObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (0.0, 5.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [0.0, 6.0, 6.0, 1.0]
ObservationTensor(0).hand_sizes = [5.0, 5.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [0.0, 6.0, 6.0, 1.0]
ObservationTensor(1).hand_sizes = [5.0, 5.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 0.0, 5.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [0.0, 6.0, 6.0, 1.0]
ObservationTensor(2).hand_sizes = [6.0, 6.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [0.0, 6.0, 6.0, 1.0]
ObservationTensor(3).hand_sizes = [6.0, 6.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [166, 169]
StringLegalActions() = ["p2 tile:(0.0, 4.0) pip:0.0", "p2 tile:(0.0, 5.0) pip:0.0"]

# Apply action "p2 tile:(0.0, 5.0) pip:0.0"
action: 169

# State 35
# hand0:['(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 1.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(5.0, 0.0), (0.0, 3.0), (3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0), (6.0, 0.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 3
InformationStateString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0]"
InformationStateString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] last_action:p2 tile:(0.0, 5.0) pip:0.0"
ObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p2 tile:(0.0, 5.0) pip:0.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] last_action:p2 tile:(0.0, 5.0) pip:0.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] last_action:p2 tile:(0.0, 5.0) pip:0.0"
PublicObservationString() = "p0 last_action:p2 tile:(0.0, 5.0) pip:0.0"
PrivateObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 1.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [0.0, 5.0, 0.0, 2.0]
ObservationTensor(0).hand_sizes = [5.0, 5.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [0.0, 5.0, 0.0, 2.0]
ObservationTensor(1).hand_sizes = [5.0, 5.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [0.0, 5.0, 0.0, 2.0]
ObservationTensor(2).hand_sizes = [5.0, 6.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [0.0, 5.0, 0.0, 2.0]
ObservationTensor(3).hand_sizes = [6.0, 5.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [232, 234, 237, 264, 289, 297]
StringLegalActions() = ["p3 tile:(0.0, 0.0) pip:0.0", "p3 tile:(0.0, 1.0) pip:0.0", "p3 tile:(0.0, 2.0) pip:0.0", "p3 tile:(1.0, 5.0) pip:5.0", "p3 tile:(3.0, 5.0) pip:5.0", "p3 tile:(4.0, 5.0) pip:5.0"]

# Apply action "p3 tile:(0.0, 1.0) pip:0.0"
action: 234

# State 36
# hand0:['(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 5.0)', '(5.0, 6.0)']
# hand1:['(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(5.0, 0.0), (0.0, 3.0), (3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0), (6.0, 0.0), (0.0, 1.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0]"
InformationStateString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)] last_action:p3 tile:(0.0, 1.0) pip:0.0"
ObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p3 tile:(0.0, 1.0) pip:0.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] last_action:p3 tile:(0.0, 1.0) pip:0.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] last_action:p3 tile:(0.0, 1.0) pip:0.0"
PublicObservationString() = "p0 last_action:p3 tile:(0.0, 1.0) pip:0.0"
PrivateObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 5.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 5.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [0.0, 1.0, 0.0, 3.0]
ObservationTensor(0).hand_sizes = [5.0, 5.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [0.0, 1.0, 0.0, 3.0]
ObservationTensor(1).hand_sizes = [5.0, 5.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [0.0, 1.0, 0.0, 3.0]
ObservationTensor(2).hand_sizes = [5.0, 5.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [0.0, 1.0, 0.0, 3.0]
ObservationTensor(3).hand_sizes = [5.0, 5.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [26, 71, 73]
StringLegalActions() = ["p0 tile:(1.0, 3.0) pip:1.0", "p0 tile:(5.0, 5.0) pip:5.0", "p0 tile:(5.0, 6.0) pip:5.0"]

# Apply action "p0 tile:(5.0, 5.0) pip:5.0"
action: 71

# State 37
# hand0:['(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 6.0)']
# hand1:['(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(1.0, 2.0)', '(2.0, 5.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(5.0, 5.0), (5.0, 0.0), (0.0, 3.0), (3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0), (6.0, 0.0), (0.0, 1.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234, 71]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234, 71"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 2
InformationStateString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0]"
InformationStateString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 6.0)] last_action:p0 tile:(5.0, 5.0) pip:5.0"
ObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p0 tile:(5.0, 5.0) pip:5.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)] last_action:p0 tile:(5.0, 5.0) pip:5.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] last_action:p0 tile:(5.0, 5.0) pip:5.0"
PublicObservationString() = "p0 last_action:p0 tile:(5.0, 5.0) pip:5.0"
PrivateObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 5.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [5.0, 5.0, 5.0, 0.0]
ObservationTensor(0).hand_sizes = [4.0, 5.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [5.0, 5.0, 5.0, 0.0]
ObservationTensor(1).hand_sizes = [5.0, 4.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [5.0, 5.0, 5.0, 0.0]
ObservationTensor(2).hand_sizes = [5.0, 5.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [5.0, 5.0, 5.0, 0.0]
ObservationTensor(3).hand_sizes = [5.0, 5.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [177, 201]
StringLegalActions() = ["p2 tile:(1.0, 2.0) pip:1.0", "p2 tile:(2.0, 5.0) pip:5.0"]

# Apply action "p2 tile:(2.0, 5.0) pip:5.0"
action: 201

# State 38
# hand0:['(1.0, 3.0)', '(2.0, 3.0)', '(4.0, 4.0)', '(5.0, 6.0)']
# hand1:['(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(1.0, 2.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 2.0)', '(1.0, 5.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(2.0, 5.0), (5.0, 5.0), (5.0, 0.0), (0.0, 3.0), (3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0), (6.0, 0.0), (0.0, 1.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234, 71, 201]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234, 71, 201"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 3
InformationStateString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0]"
InformationStateString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 6.0)] last_action:p2 tile:(2.0, 5.0) pip:5.0"
ObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p2 tile:(2.0, 5.0) pip:5.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 6.0), (6.0, 6.0)] last_action:p2 tile:(2.0, 5.0) pip:5.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)] last_action:p2 tile:(2.0, 5.0) pip:5.0"
PublicObservationString() = "p0 last_action:p2 tile:(2.0, 5.0) pip:5.0"
PrivateObservationString(0) = "p0 hand:[(1.0, 3.0), (2.0, 3.0), (4.0, 4.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (1.0, 5.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [2.0, 5.0, 5.0, 2.0]
ObservationTensor(0).hand_sizes = [4.0, 5.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [2.0, 5.0, 5.0, 2.0]
ObservationTensor(1).hand_sizes = [5.0, 4.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [2.0, 5.0, 5.0, 2.0]
ObservationTensor(2).hand_sizes = [4.0, 5.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [2.0, 5.0, 5.0, 2.0]
ObservationTensor(3).hand_sizes = [5.0, 4.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [238, 263]
StringLegalActions() = ["p3 tile:(0.0, 2.0) pip:2.0", "p3 tile:(1.0, 5.0) pip:1.0"]

# Apply action "p3 tile:(1.0, 5.0) pip:1.0"
action: 263

# State 39
# Apply action "p0 tile:(2.0, 3.0) pip:2.0"
action: 40

# State 40
# hand0:['(1.0, 3.0)', '(4.0, 4.0)', '(5.0, 6.0)']
# hand1:['(2.0, 2.0)', '(2.0, 4.0)', '(3.0, 3.0)', '(3.0, 6.0)', '(4.0, 6.0)']
# hand2:['(0.0, 4.0)', '(1.0, 2.0)', '(2.0, 6.0)', '(6.0, 6.0)']
# hand3:['(0.0, 0.0)', '(0.0, 2.0)', '(3.0, 5.0)', '(4.0, 5.0)']
#
# board: [(3.0, 2.0), (2.0, 5.0), (5.0, 5.0), (5.0, 0.0), (0.0, 3.0), (3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0), (6.0, 0.0), (0.0, 1.0), (1.0, 5.0)]
IsTerminal() = False
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234, 71, 201, 263, 40]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234, 71, 201, 263, 40"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "p0 hand:[(1.0, 3.0), (4.0, 4.0), (5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0, p3 tile:(1.0, 5.0) pip:1.0, p0 tile:(2.0, 3.0) pip:2.0]"
InformationStateString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0, p3 tile:(1.0, 5.0) pip:1.0, p0 tile:(2.0, 3.0) pip:2.0]"
InformationStateString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 6.0), (6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0, p3 tile:(1.0, 5.0) pip:1.0, p0 tile:(2.0, 3.0) pip:2.0]"
InformationStateString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (3.0, 5.0), (4.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0, p3 tile:(1.0, 5.0) pip:1.0, p0 tile:(2.0, 3.0) pip:2.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [1.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(1.0, 3.0), (4.0, 4.0), (5.0, 6.0)] last_action:p0 tile:(2.0, 3.0) pip:2.0"
ObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)] last_action:p0 tile:(2.0, 3.0) pip:2.0"
ObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 6.0), (6.0, 6.0)] last_action:p0 tile:(2.0, 3.0) pip:2.0"
ObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (3.0, 5.0), (4.0, 5.0)] last_action:p0 tile:(2.0, 3.0) pip:2.0"
PublicObservationString() = "p0 last_action:p0 tile:(2.0, 3.0) pip:2.0"
PrivateObservationString(0) = "p0 hand:[(1.0, 3.0), (4.0, 4.0), (5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(2.0, 2.0), (2.0, 4.0), (3.0, 3.0), (3.0, 6.0), (4.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(0.0, 4.0), (1.0, 2.0), (2.0, 6.0), (6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(0.0, 0.0), (0.0, 2.0), (3.0, 5.0), (4.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [1.0, 3.0, 1.0, 4.0, 4.0, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [2.0, 3.0, 2.0, 0.0]
ObservationTensor(0).hand_sizes = [3.0, 5.0, 0.0, 0.0]
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 1.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [2.0, 3.0, 2.0, 0.0]
ObservationTensor(1).hand_sizes = [5.0, 3.0, 0.0, 0.0]
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 6.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [2.0, 3.0, 2.0, 0.0]
ObservationTensor(2).hand_sizes = [4.0, 4.0, 0.0, 0.0]
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [2.0, 3.0, 2.0, 0.0]
ObservationTensor(3).hand_sizes = [4.0, 4.0, 0.0, 0.0]
Rewards() = [0, 0, 0, 0]
Returns() = [0, 0, 0, 0]
LegalActions() = [129, 137]
StringLegalActions() = ["p1 tile:(3.0, 3.0) pip:3.0", "p1 tile:(3.0, 6.0) pip:3.0"]

# Apply action "p1 tile:(3.0, 3.0) pip:3.0"
action: 129

# State 41
# Apply action "p3 tile:(4.0, 5.0) pip:5.0"
action: 297

# State 42
# Apply action "p0 tile:(4.0, 4.0) pip:4.0"
action: 63

# State 43
# Apply action "p1 tile:(4.0, 6.0) pip:4.0"
action: 145

# State 44
# Apply action "p2 tile:(2.0, 6.0) pip:6.0"
action: 204

# State 45
# Apply action "p3 tile:(0.0, 2.0) pip:2.0"
action: 238

# State 46
# Apply action "p0 tile:(1.0, 3.0) pip:3.0"
action: 27

# State 47
# Apply action "p2 tile:(1.0, 2.0) pip:1.0"
action: 177

# State 48
# Apply action "p3 tile:(0.0, 0.0) pip:0.0"
action: 232

# State 49
# Apply action "p1 tile:(2.0, 2.0) pip:2.0"
action: 115

# State 50
# Apply action "p2 tile:(0.0, 4.0) pip:0.0"
action: 166

# State 51
# Apply action "p1 tile:(2.0, 4.0) pip:2.0"
action: 120

# State 52
# hand0:['(5.0, 6.0)']
# hand1:['(3.0, 6.0)']
# hand2:['(6.0, 6.0)']
# hand3:['(3.0, 5.0)']
#
# board: [(4.0, 2.0), (2.0, 2.0), (2.0, 1.0), (1.0, 3.0), (3.0, 3.0), (3.0, 2.0), (2.0, 5.0), (5.0, 5.0), (5.0, 0.0), (0.0, 3.0), (3.0, 4.0), (4.0, 1.0), (1.0, 1.0), (1.0, 6.0), (6.0, 0.0), (0.0, 1.0), (1.0, 5.0), (5.0, 4.0), (4.0, 4.0), (4.0, 6.0), (6.0, 2.0), (2.0, 0.0), (0.0, 0.0), (0.0, 4.0)]
IsTerminal() = True
History() = [9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234, 71, 201, 263, 40, 129, 297, 63, 145, 204, 238, 27, 177, 232, 115, 166, 120]
HistoryString() = "9, 18, 5, 11, 14, 15, 19, 12, 26, 21, 27, 20, 7, 6, 4, 1, 25, 24, 8, 23, 3, 10, 17, 2, 22, 13, 16, 0, 20, 106, 209, 266, 10, 96, 169, 234, 71, 201, 263, 40, 129, 297, 63, 145, 204, 238, 27, 177, 232, 115, 166, 120"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = PlayerId.TERMINAL
InformationStateString(0) = "p0 hand:[(5.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0, p3 tile:(1.0, 5.0) pip:1.0, p0 tile:(2.0, 3.0) pip:2.0, p1 tile:(3.0, 3.0) pip:3.0, p3 tile:(4.0, 5.0) pip:5.0, p0 tile:(4.0, 4.0) pip:4.0, p1 tile:(4.0, 6.0) pip:4.0, p2 tile:(2.0, 6.0) pip:6.0, p3 tile:(0.0, 2.0) pip:2.0, p0 tile:(1.0, 3.0) pip:3.0, p2 tile:(1.0, 2.0) pip:1.0, p3 tile:(0.0, 0.0) pip:0.0, p1 tile:(2.0, 2.0) pip:2.0, p2 tile:(0.0, 4.0) pip:0.0, p1 tile:(2.0, 4.0) pip:2.0]"
InformationStateString(1) = "p1 hand:[(3.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0, p3 tile:(1.0, 5.0) pip:1.0, p0 tile:(2.0, 3.0) pip:2.0, p1 tile:(3.0, 3.0) pip:3.0, p3 tile:(4.0, 5.0) pip:5.0, p0 tile:(4.0, 4.0) pip:4.0, p1 tile:(4.0, 6.0) pip:4.0, p2 tile:(2.0, 6.0) pip:6.0, p3 tile:(0.0, 2.0) pip:2.0, p0 tile:(1.0, 3.0) pip:3.0, p2 tile:(1.0, 2.0) pip:1.0, p3 tile:(0.0, 0.0) pip:0.0, p1 tile:(2.0, 2.0) pip:2.0, p2 tile:(0.0, 4.0) pip:0.0, p1 tile:(2.0, 4.0) pip:2.0]"
InformationStateString(2) = "p2 hand:[(6.0, 6.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0, p3 tile:(1.0, 5.0) pip:1.0, p0 tile:(2.0, 3.0) pip:2.0, p1 tile:(3.0, 3.0) pip:3.0, p3 tile:(4.0, 5.0) pip:5.0, p0 tile:(4.0, 4.0) pip:4.0, p1 tile:(4.0, 6.0) pip:4.0, p2 tile:(2.0, 6.0) pip:6.0, p3 tile:(0.0, 2.0) pip:2.0, p0 tile:(1.0, 3.0) pip:3.0, p2 tile:(1.0, 2.0) pip:1.0, p3 tile:(0.0, 0.0) pip:0.0, p1 tile:(2.0, 2.0) pip:2.0, p2 tile:(0.0, 4.0) pip:0.0, p1 tile:(2.0, 4.0) pip:2.0]"
InformationStateString(3) = "p3 hand:[(3.0, 5.0)] history:[p0 tile:(1.0, 1.0) pip:None, p1 tile:(1.0, 4.0) pip:1.0, p2 tile:(3.0, 4.0) pip:4.0, p3 tile:(1.0, 6.0) pip:1.0, p0 tile:(0.0, 3.0) pip:3.0, p1 tile:(0.0, 6.0) pip:6.0, p2 tile:(0.0, 5.0) pip:0.0, p3 tile:(0.0, 1.0) pip:0.0, p0 tile:(5.0, 5.0) pip:5.0, p2 tile:(2.0, 5.0) pip:5.0, p3 tile:(1.0, 5.0) pip:1.0, p0 tile:(2.0, 3.0) pip:2.0, p1 tile:(3.0, 3.0) pip:3.0, p3 tile:(4.0, 5.0) pip:5.0, p0 tile:(4.0, 4.0) pip:4.0, p1 tile:(4.0, 6.0) pip:4.0, p2 tile:(2.0, 6.0) pip:6.0, p3 tile:(0.0, 2.0) pip:2.0, p0 tile:(1.0, 3.0) pip:3.0, p2 tile:(1.0, 2.0) pip:1.0, p3 tile:(0.0, 0.0) pip:0.0, p1 tile:(2.0, 2.0) pip:2.0, p2 tile:(0.0, 4.0) pip:0.0, p1 tile:(2.0, 4.0) pip:2.0]"
InformationStateTensor(0).player: ◉◯◯◯
InformationStateTensor(0).hand = [5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(0).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 4.0, 5.0, 5.0, 3.0, 1.0, 4.0, 4.0, 4.0, 0.0, 1.0, 4.0, 6.0, 4.0, 1.0, 1.0, 2.0, 6.0, 6.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).player: ◯◉◯◯
InformationStateTensor(1).hand = [3.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 4.0, 5.0, 5.0, 3.0, 1.0, 4.0, 4.0, 4.0, 0.0, 1.0, 4.0, 6.0, 4.0, 1.0, 1.0, 2.0, 6.0, 6.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).player: ◯◯◉◯
InformationStateTensor(2).hand = [6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(2).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 4.0, 5.0, 5.0, 3.0, 1.0, 4.0, 4.0, 4.0, 0.0, 1.0, 4.0, 6.0, 4.0, 1.0, 1.0, 2.0, 6.0, 6.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).player: ◯◯◯◉
InformationStateTensor(3).hand = [3.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
InformationStateTensor(3).actions_history = [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 1.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 6.0, 6.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 5.0, 5.0, 5.0, 0.0, 1.0, 2.0, 5.0, 5.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 4.0, 5.0, 5.0, 3.0, 1.0, 4.0, 4.0, 4.0, 0.0, 1.0, 4.0, 6.0, 4.0, 1.0, 1.0, 2.0, 6.0, 6.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationString(0) = "p0 hand:[(5.0, 6.0)] last_action:p1 tile:(2.0, 4.0) pip:2.0"
ObservationString(1) = "p1 hand:[(3.0, 6.0)] last_action:p1 tile:(2.0, 4.0) pip:2.0"
ObservationString(2) = "p2 hand:[(6.0, 6.0)] last_action:p1 tile:(2.0, 4.0) pip:2.0"
ObservationString(3) = "p3 hand:[(3.0, 5.0)] last_action:p1 tile:(2.0, 4.0) pip:2.0"
PublicObservationString() = "p0 last_action:p1 tile:(2.0, 4.0) pip:2.0"
PrivateObservationString(0) = "p0 hand:[(5.0, 6.0)]"
PrivateObservationString(1) = "p1 hand:[(3.0, 6.0)]"
PrivateObservationString(2) = "p2 hand:[(6.0, 6.0)]"
PrivateObservationString(3) = "p3 hand:[(3.0, 5.0)]"
ObservationTensor(0).player: ◉◯◯◯
ObservationTensor(0).hand = [5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(0).last_action = [2.0, 4.0, 2.0, 1.0]
ObservationTensor(0).hand_sizes: ◉◉◯◯
ObservationTensor(1).player: ◯◉◯◯
ObservationTensor(1).hand = [3.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(1).last_action = [2.0, 4.0, 2.0, 1.0]
ObservationTensor(1).hand_sizes: ◉◉◯◯
ObservationTensor(2).player: ◯◯◉◯
ObservationTensor(2).hand = [6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(2).last_action = [2.0, 4.0, 2.0, 1.0]
ObservationTensor(2).hand_sizes: ◉◉◯◯
ObservationTensor(3).player: ◯◯◯◉
ObservationTensor(3).hand = [3.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ObservationTensor(3).last_action = [2.0, 4.0, 2.0, 1.0]
ObservationTensor(3).hand_sizes: ◉◉◯◯
Rewards() = [-23, 23, -23, 23]
Returns() = [-23, 23, -23, 23]
